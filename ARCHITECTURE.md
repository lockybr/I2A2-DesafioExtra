# üè¢Ô∏è Arquitetura do I2A2 EDA Agent v2.0.3

## Vis√£o Geral

O **I2A2 EDA Agent** √© uma aplica√ß√£o modular de an√°lise explorat√≥ria de dados que utiliza m√∫ltiplas LLMs para automatizar e otimizar o processo de an√°lise. A arquitetura foi projetada para ser escal√°vel, mant√≠vel e facilmente extens√≠vel.

**Powered by Saulo Belchior** - Vers√£o 2.0.3 com Sistema Multi-LLM
 
 ### Diagrama de Vis√£o Geral (Mermaid)
 
 ```mermaid
 graph LR
   U[Usu√°rio] --> UI[Streamlit UI]
   UI --> A[LangChain Agent]
   A -- Mem√≥ria --> M[Conversation Memory]
   A -- Ferramentas --> T[Tools (EDA/Visualizations/Insights)]
   T --> D[Pandas DataFrame]
   A -- LLM --> L[Multi-LLM System\nxAI Grok | Meta Llama 3.2 | DeepSeek]
   L --> F[Fallback Manager]
   F --> S[Model Selector]
   S --> O[Offline Agent]
   A --> R[Respostas/Gr√°ficos]
   R --> UI
```
 
 ### Diagrama de Vis√£o Geral (ASCII)
 
 ```text
 +------------------+       +---------------------+       +------------------+
 |      Usu√°rio     | --->  |     Streamlit UI    | --->  |  LangChain Agent |
 +------------------+       +---------------------+       +------------------+
                                    |   ^                          |
                                    v   |                          v
                             +-----------------+           +------------------+
                             |  Respostas/UX   |<----------|  Conversation    |
                             +-----------------+           |     Memory       |
                                                            +------------------+
                                    |
                                    v
                          +---------------------+
                          |       Tools         |
                          | (EDA / Visual / etc)|
                          +----------+----------+
                                     |
                                     v
                       +-------------------------------+
                       |      Multi-LLM System         |
                       | xAI Grok 4 Fast              |
                       | Meta Llama 3.2 3B            |
                       | DeepSeek Free                 |
                       +---------------+---------------+
                                       |
                                       v
                               +---------------+
                               | Model Selector|
                               | & Transparency|
                               +---------------+
 
 ## üß∞ Framework escolhido: LangChain
 
 O projeto adota LangChain como framework central para aplica√ß√µes com LLMs. Dentro desta arquitetura, ele:
 - **Define Tools nativas (`@tool`)**: converte fun√ß√µes Python (em `tools/`) em ferramentas com JSON Schema prontas para tool-calling por LLMs.
 - **Orquestra com AgentExecutor**: recebe o LLM, as ferramentas e o input do usu√°rio; formata prompt, chama o LLM, interpreta ferramenta/argumentos, executa, e (opcionalmente) sintetiza a resposta final; tamb√©m gerencia mem√≥ria/hist√≥rico.
 - **Fornece Mem√≥ria Conversacional**: com `ConversationSummaryBufferMemory`/`ConversationBufferWindowMemory` para manter contexto entre intera√ß√µes.
 - **Integra f√°cil com m√∫ltiplos provedores**: OpenRouter/OpenAI/Groq/Gemini/Ollama, reduzindo configura√ß√£o e boilerplate.
 
 Benef√≠cio no projeto: focamos na l√≥gica de neg√≥cio (tools e UI) enquanto o LangChain cuida da mec√¢nica agente‚ÜîLLM‚Üîferramentas e da consist√™ncia do hist√≥rico.

## üåê Sistema Multi-LLM

### Modelos Dispon√≠veis

1. **xAI Grok 4 Fast**
   - Contexto: 2M tokens
   - Rate Limit: 100 req/dia
   - Caracter√≠sticas: Modelo mais avan√ßado, ideal para an√°lises complexas

2. **Meta Llama 3.2 3B**
   - Contexto: 128k tokens
   - Rate Limit: 200 req/dia
   - Caracter√≠sticas: Balan√ßo entre performance e velocidade

3. **DeepSeek Free**
   - Contexto: 256k tokens
   - Rate Limit: 50 req/dia
   - Caracter√≠sticas: Especializado em c√≥digo e an√°lise t√©cnica

### Sistema de Fallback

```python
class LLMFallbackManager:
    def get_llm(self, force_provider=None):
        # 1. Se usu√°rio selecionou modelo espec√≠fico
        if force_provider is not None:
            return self._create_llm(providers[force_provider])
        
        # 2. Tentar modelos em ordem de prioridade
        for provider in providers:
            try:
                if self._is_available(provider):
                    return self._create_llm(provider)
            except Exception:
                continue
        
        # 3. Fallback para modo offline
        return OfflineAgent()
```

### Transpar√™ncia e Rastreamento

- **Cabe√ßalho nas Respostas**: Cada resposta inclui informa√ß√µes do modelo usado
- **Status na Sidebar**: Mostra modelo ativo em tempo real
- **Logs Detalhados**: Rastreamento completo de qual modelo foi usado
- **Callback Personalizado**: Mostra modelo correto nos logs de execu√ß√£o
 
 ## Componentes Principais

### üõ†Ô∏è Tools Module
**Responsabilidade:** Ferramentas de an√°lise de dados

```python
tools/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ data_analysis.py    # An√°lise estat√≠stica
‚îú‚îÄ‚îÄ visualizations.py   # Gr√°ficos e visualiza√ß√µes
‚îî‚îÄ‚îÄ insights.py        # Gera√ß√£o de insights
```

**Ferramentas Dispon√≠veis:**
1. `get_data_description`: Vis√£o geral do dataset
2. `get_descriptive_statistics`: Estat√≠sticas descritivas
3. `plot_histogram`: Distribui√ß√£o de dados
4. `plot_boxplot`: An√°lise de outliers (individual)
5. `plot_multiple_boxplots`: An√°lise de outliers (m√∫ltipla)
6. `plot_correlation_heatmap`: Correla√ß√µes entre vari√°veis
7. `plot_scatter`: Rela√ß√µes bivariadas
8. `generate_insights_and_conclusions`: S√≠ntese de an√°lises

### üõ†Ô∏è Utils Module
**Responsabilidade:** Fun√ß√µes auxiliares e utilit√°rios

```python
utils/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ callbacks.py    # Callbacks para feedback visual
‚îú‚îÄ‚îÄ memory.py      # Gerenciamento de mem√≥ria
‚îî‚îÄ‚îÄ logger.py      # Sistema de logging
```

**Funcionalidades:**
- **Callbacks:** Feedback em tempo real do processamento
- **Memory:** Gerenciamento de contexto conversacional
- **Logger:** Sistema unificado de logging

### üé® UI Module
**Responsabilidade:** Componentes de interface do usu√°rio

```python
ui/
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ components.py   # Componentes reutiliz√°veis
```

**Componentes:**
- `render_sidebar()`: Barra lateral com upload
- `render_chat_interface()`: Interface de chat principal
- `render_suggestions()`: Sugest√µes de perguntas
- `render_history()`: Hist√≥rico de an√°lises
- `initialize_session_state()`: Estado da sess√£o

## Fluxo de Execu√ß√£o

### 1. Inicializa√ß√£o
```
app.py ‚Üí setup_logging() ‚Üí initialize_session_state() ‚Üí render UI
```

### 2. Upload de Dados
```
User Upload ‚Üí render_sidebar() ‚Üí pd.read_csv() ‚Üí create_eda_agent()
```

### 3. Processamento de Pergunta
```
User Input ‚Üí render_chat_interface() ‚Üí agent_executor.invoke() ‚Üí Tool Selection ‚Üí Tool Execution ‚Üí Result Display
```

### 4. Gera√ß√£o de Insights
```
Analysis History ‚Üí generate_insights_and_conclusions() ‚Üí Statistical Analysis ‚Üí Pattern Detection ‚Üí Recommendations
```

## Diagrama de Sequ√™ncia

```mermaid
sequenceDiagram
    participant U as User
    participant UI as UI Layer
    participant A as Agent
    participant LLM as DeepSeek
    participant T as Tools
    participant M as Memory

    U->>UI: Upload CSV
    UI->>A: Create Agent
    A->>M: Initialize Memory
    
    U->>UI: Ask Question
    UI->>A: Process Query
    A->>M: Load Context
    A->>LLM: Analyze Query
    LLM->>A: Select Tool
    A->>T: Execute Tool
    T->>A: Return Result
    A->>M: Save to Memory
    A->>UI: Display Result
    UI->>U: Show Analysis
```

## Padr√µes de Design Utilizados

### 1. **Factory Pattern**
- `create_eda_agent()`: Cria√ß√£o de agentes
- `create_memory()`: Cria√ß√£o de mem√≥ria

### 2. **Decorator Pattern**
- `@tool`: Decorador para ferramentas LangChain
- Callbacks para interceptar execu√ß√£o

### 3. **Singleton Pattern**
- `settings`: Inst√¢ncia √∫nica de configura√ß√µes
- Session state do Streamlit

### 4. **Strategy Pattern**
- Diferentes ferramentas como estrat√©gias de an√°lise
- Sele√ß√£o din√¢mica baseada no contexto

## Vantagens da Arquitetura

### ‚úÖ Manutenibilidade
- C√≥digo organizado em m√≥dulos espec√≠ficos
- Responsabilidades bem definidas
- F√°cil localiza√ß√£o de bugs

### ‚úÖ Escalabilidade
- Novos m√≥dulos podem ser adicionados facilmente
- Ferramentas independentes
- Configura√ß√£o centralizada

### ‚úÖ Testabilidade
- Componentes isolados
- Mocks facilitados
- Testes unit√°rios por m√≥dulo

### ‚úÖ Reutiliza√ß√£o
- Componentes gen√©ricos em utils/
- UI components reutiliz√°veis
- Configura√ß√µes compartilhadas

## Como Adicionar Novas Funcionalidades

### Adicionar Nova Ferramenta
1. Criar fun√ß√£o em `tools/` com decorador `@tool`
2. Adicionar √† lista `ALL_TOOLS` em `tools/__init__.py`
3. Atualizar prompt do agente se necess√°rio

### Adicionar Novo Tipo de Visualiza√ß√£o
1. Implementar em `tools/visualizations.py`
2. Seguir padr√£o de retorno `go.Figure`
3. Adicionar tratamento de erros

### Modificar Configura√ß√µes
1. Editar `config/settings.py`
2. Usar `settings.CATEGORIA["parametro"]`
3. Reiniciar aplica√ß√£o

### Adicionar Novo Agente
1. Criar arquivo em `agents/`
2. Implementar fun√ß√£o de cria√ß√£o
3. Registrar em `agents/__init__.py`

## Performance e Otimiza√ß√µes

### Mem√≥ria
- Window-based memory (√∫ltimas 10 intera√ß√µes)
- Evita overflow de contexto
- Carregamento sob demanda

### Processamento
- Ferramentas executam localmente
- Apenas decis√µes v√£o para LLM
- Cache de resultados no session_state

### UI
- Componentes lazy-loaded
- Estados preservados na sess√£o
- Feedback visual instant√¢neo

## Seguran√ßa

### Dados
- Processamento 100% local
- N√£o h√° envio de dados para APIs externas
- Apenas perguntas s√£o enviadas ao LLM

### API Keys
- Podem ser configuradas via vari√°veis de ambiente
- Fallback para valores padr√£o em desenvolvimento
- N√£o expostas no c√≥digo de produ√ß√£o

## Deployment

### Requisitos
- Python 3.8+
- Depend√™ncias em `requirements.txt`
- 2GB RAM m√≠nimo recomendado

### Configura√ß√£o para Produ√ß√£o
1. Definir vari√°veis de ambiente
2. Ajustar `settings.py` para produ√ß√£o
3. Configurar logging apropriado
4. Implementar rate limiting se necess√°rio

## Roadmap Futuro

### v2.1 (Planejado)
- [ ] Suporte para m√∫ltiplos formatos (Excel, JSON)
- [ ] Cache de an√°lises frequentes
- [ ] Export de relat√≥rios em PDF

### v2.2 (Conceitual)
- [ ] Machine Learning autom√°tico
- [ ] An√°lise preditiva
- [ ] Integra√ß√£o com bases de dados

### v3.0 (Vis√£o)
- [ ] Multi-agente colaborativo
- [ ] AutoML integrado
- [ ] Dashboard customiz√°vel

## Contribuindo

Para contribuir com o projeto:
1. Fork o reposit√≥rio
2. Crie branch para feature (`git checkout -b feature/nova-funcionalidade`)
3. Siga os padr√µes de c√≥digo estabelecidos
4. Adicione testes quando aplic√°vel
5. Fa√ßa PR com descri√ß√£o detalhada

## Suporte

Para quest√µes sobre a arquitetura:
- Consulte este documento
- Verifique os coment√°rios no c√≥digo
- Abra uma issue no reposit√≥rio
