"""
Componentes da interface do usu√°rio.
"""

import streamlit as st
import pandas as pd
import logging
import traceback
from datetime import datetime

from agents import create_eda_agent

logger = logging.getLogger(__name__)


def initialize_session_state():
    """Inicializa as vari√°veis de estado da sess√£o."""
    if 'df' not in st.session_state:
        st.session_state.df = None
        logger.info("Initialized df in session_state")
    if 'agent_executor' not in st.session_state:
        st.session_state.agent_executor = None
        logger.info("Initialized agent_executor in session_state")
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
        logger.info("Initialized chat_history in session_state")
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        logger.info("Initialized messages in session_state")
    if 'processing_steps' not in st.session_state:
        st.session_state.processing_steps = []
        logger.info("Initialized processing_steps in session_state")
    if 'analysis_history' not in st.session_state:
        st.session_state.analysis_history = []
        logger.info("Initialized analysis_history in session_state")
    if 'agent_memory' not in st.session_state:
        st.session_state.agent_memory = None
        logger.info("Initialized agent_memory in session_state")


def render_sidebar():
    """Renderiza a barra lateral com upload de arquivo e informa√ß√µes."""
    with st.sidebar:
        st.header("üìÅ Configura√ß√£o de Dados")
        
        # Upload de arquivo
        uploaded_file = st.file_uploader(
            "Selecione um arquivo CSV",
            type=['csv'],
            help="Fa√ßa upload de um arquivo CSV para come√ßar a an√°lise"
        )
        
        # Seletor de LLM
        st.header("ü§ñ Sele√ß√£o de Modelo")
        
        from config.settings_alternatives import alternative_settings
        
        # Obter lista de modelos gratuitos
        free_models = []
        model_info = {}
        
        for i, provider in enumerate(alternative_settings.get_fallback_configs()):
            if provider.get('is_free', False):
                display_name = f"{provider['name']}"
                if provider.get('rate_limit'):
                    display_name += f" ({provider['rate_limit']} req/dia)"
                else:
                    display_name += " (Ilimitado)"
                    
                free_models.append(display_name)
                model_info[display_name] = {
                    'index': i,
                    'name': provider['name'],
                    'model': provider['config']['model_name'],
                    'rate_limit': provider.get('rate_limit'),
                    'context': provider.get('context_length', 'N/A')
                }
        
        # Adicionar op√ß√£o de fallback autom√°tico
        free_models.insert(0, "üîÑ Fallback Autom√°tico (Recomendado)")
        model_info["üîÑ Fallback Autom√°tico (Recomendado)"] = {
            'index': None,
            'name': 'Fallback Autom√°tico',
            'model': 'M√∫ltiplos modelos',
            'rate_limit': 'Vari√°vel'
        }
        
        selected_model = st.selectbox(
            "Escolha o modelo LLM:",
            options=free_models,
            index=0,
            help="Selecione qual modelo usar para an√°lise. O fallback autom√°tico tentar√° v√°rios modelos em ordem de prioridade."
        )
        
        # Mostrar informa√ß√µes do modelo selecionado
        if selected_model in model_info:
            info = model_info[selected_model]
            with st.expander("‚ÑπÔ∏è Informa√ß√µes do Modelo", expanded=False):
                st.write(f"**Nome:** {info['name']}")
                st.write(f"**Modelo:** `{info['model']}`")
                st.write(f"**Rate Limit:** {info['rate_limit']}")
                if info.get('context'):
                    st.write(f"**Contexto:** {info['context']}")
        
        # Armazenar sele√ß√£o no session_state
        st.session_state.selected_model_index = model_info[selected_model]['index']
        
        # Bot√£o para aplicar mudan√ßa de modelo
        if st.button("üîÑ Aplicar Modelo Selecionado", help="Reconfigura o agente com o modelo selecionado"):
            # For√ßar recria√ß√£o do agente
            st.session_state.agent_executor = None
            if hasattr(st.session_state, 'current_model_index'):
                del st.session_state.current_model_index
            st.rerun()
        
        if uploaded_file is not None:
            try:
                # Mostrar status de carregamento
                status_container = st.container()
                with status_container:
                    with st.spinner("üìÇ Carregando arquivo..."):
                        logger.info(f"Loading file: {uploaded_file.name}")
                        df = pd.read_csv(uploaded_file)
                        st.session_state.df = df
                        logger.info(f"File loaded successfully: {df.shape}")
                    
                    st.success(f"‚úÖ Arquivo carregado: {df.shape[0]:,} linhas √ó {df.shape[1]} colunas")
                
                # Verificar se precisa recriar o agente (modelo mudou ou n√£o existe)
                need_recreate = (
                    st.session_state.agent_executor is None or
                    not hasattr(st.session_state, 'current_model_index') or
                    st.session_state.current_model_index != st.session_state.selected_model_index
                )
                
                if need_recreate:
                    with status_container:
                        with st.spinner("üîß Configurando agente de an√°lise..."):
                            # IMPORTANTE: Garantir que o DataFrame est√° dispon√≠vel antes de criar o agente
                            logger.info(f"Creating agent with DataFrame shape: {st.session_state.df.shape}")
                            
                            # Mostrar qual modelo ser√° usado
                            if st.session_state.selected_model_index is not None:
                                from config.settings_alternatives import alternative_settings
                                selected_provider = alternative_settings.get_fallback_configs()[st.session_state.selected_model_index]
                                st.info(f"üéØ Configurando com {selected_provider['name']}...")
                            else:
                                st.info("üîÑ Configurando com fallback autom√°tico...")
                            
                            # Recriar o agente (o DataFrame j√° est√° em st.session_state.df)
                            st.session_state.agent_executor = create_eda_agent()
                            
                            # Armazenar o √≠ndice do modelo atual
                            st.session_state.current_model_index = st.session_state.selected_model_index
                            
                            # Verificar se o DataFrame ainda est√° dispon√≠vel ap√≥s criar o agente
                            if st.session_state.df is not None:
                                logger.info(f"DataFrame verified after agent creation: {st.session_state.df.shape}")
                            else:
                                logger.error("DataFrame was lost after agent creation!")
                            
                            # Mostrar qual modelo foi realmente usado
                            from utils.llm_fallback import llm_fallback_manager
                            provider_info = llm_fallback_manager.get_current_provider_info()
                            if provider_info['name'] != 'Nenhum':
                                st.success(f"‚úÖ Agente configurado com {provider_info['name']}!")
                            else:
                                st.success("‚úÖ Agente configurado com sucesso!")
                            logger.info(f"Agent configured and ready with model index: {st.session_state.selected_model_index}")
                
                # Mostrar informa√ß√µes b√°sicas
                st.markdown("### üìä Dataset Carregado")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Total de Linhas", f"{df.shape[0]:,}")
                with col2:
                    st.metric("Total de Colunas", df.shape[1])
                
                # Preview dos dados
                with st.expander("üëÄ Preview dos Dados", expanded=True):
                    tab1, tab2, tab3 = st.tabs(["Primeiras linhas", "√öltimas linhas", "Amostra aleat√≥ria"])
                    with tab1:
                        st.dataframe(df.head(10))
                    with tab2:
                        st.dataframe(df.tail(10))
                    with tab3:
                        st.dataframe(df.sample(min(10, len(df))))
                
                # Mostrar colunas dispon√≠veis
                with st.expander("üìã Colunas Dispon√≠veis"):
                    cols_info = pd.DataFrame({
                        'Coluna': df.columns,
                        'Tipo': df.dtypes.astype(str),
                        'N√£o-Nulos': df.count()
                    })
                    st.dataframe(cols_info)
                
                # Mostrar status do modelo atual
                st.markdown("### ü§ñ Status do Modelo")
                if st.session_state.agent_executor is not None:
                    from utils.llm_fallback import llm_fallback_manager
                    provider_info = llm_fallback_manager.get_current_provider_info()
                    
                    if provider_info['name'] != 'Nenhum':
                        st.info(f"**Modelo Ativo:** {provider_info['name']}")
                        st.caption(f"üìã {provider_info['model']}")
                        st.caption(f"üí∞ {'Gratuito' if provider_info.get('is_free') else 'Pago'}")
                        if provider_info.get('rate_limit'):
                            st.caption(f"‚è±Ô∏è {provider_info['rate_limit']} req/dia")
                        
                        # Mostrar se est√° usando modelo selecionado ou fallback
                        if st.session_state.selected_model_index is not None:
                            st.caption("üéØ Modelo selecionado manualmente")
                        else:
                            st.caption("üîÑ Fallback autom√°tico ativo")
                    else:
                        st.warning("‚ö†Ô∏è Nenhum modelo ativo")
                else:
                    st.warning("‚ö†Ô∏è Agente n√£o configurado")
                    
            except Exception as e:
                logger.error(f"Error loading file: {e}")
                logger.error(traceback.format_exc())
                st.error(f"‚ùå Erro ao carregar arquivo: {str(e)}")
                with st.expander("üîç Detalhes do erro"):
                    st.code(traceback.format_exc())
                st.session_state.df = None
                st.session_state.agent_executor = None
        
        # Bot√£o para limpar sess√£o
        if st.button("üîÑ Nova An√°lise"):
            logger.info("Clearing session state")
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()


def render_chat_interface():
    """Renderiza a interface de chat principal."""
    if st.session_state.df is not None and st.session_state.agent_executor is not None:
        
        # Container para mensagens do chat
        st.subheader("üí¨ Chat de An√°lise")
        
        # Exibir hist√≥rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if message["role"] == "user":
                    st.write(message["content"])
                else:
                    # Para mensagens do assistente, verificar se h√° figuras
                    if "figure" in message:
                        st.plotly_chart(message["figure"], use_container_width=True)
                    else:
                        st.write(message["content"])
        
        # Input do usu√°rio
        if prompt := st.chat_input("Digite sua pergunta sobre os dados..."):
            # Adicionar mensagem do usu√°rio
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)
            
            # Processar com o agente
            _process_user_query(prompt)
    else:
        # Mensagem quando n√£o h√° dados carregados
        st.info("üëà Por favor, fa√ßa upload de um arquivo CSV na barra lateral para come√ßar a an√°lise.")


def _process_user_query(prompt: str):
    """Processa a pergunta do usu√°rio com o agente."""
    import io
    import sys
    import plotly.graph_objects as go
    from langchain_core.messages import HumanMessage, AIMessage
    from utils.callbacks import StreamlitCallbackHandler
    from utils.memory import save_to_history
    
    with st.chat_message("assistant"):
        # Container para mostrar progresso
        progress_container = st.container()
        result_container = st.container()
        
        with progress_container:
            status_placeholder = st.empty()
            progress_placeholder = st.empty()
            
            try:
                # Criar callback handler
                callback_handler = StreamlitCallbackHandler(progress_placeholder)
                
                # Status inicial
                status_placeholder.info("üîç Processando sua pergunta...")
                logger.info(f"Processing user input: {prompt}")
                
                # Redirecionar stdout temporariamente para capturar prints
                old_stdout = sys.stdout
                sys.stdout = io.StringIO()
                
                # Executar o agente com callbacks
                try:
                    result = st.session_state.agent_executor.invoke(
                        {"input": prompt},
                        {"callbacks": [callback_handler]}
                    )
                except (NotImplementedError, Exception) as nie:
                    # Verificar se √© erro de rate limit
                    if "429" in str(nie) or "rate limit" in str(nie).lower():
                        logger.warning(f"Rate limit detected: {nie}")
                        st.error("‚ö†Ô∏è Limite de requisi√ß√µes excedido. Mudando para modo offline...")
                        
                        # Usar agente offline
                        from agents.offline_agent import offline_agent
                        result = offline_agent.invoke({"input": prompt})
                        
                    else:
                        # Outros erros - tentar sem mem√≥ria
                        logger.warning(f"Memory issue detected: {nie}")
                        logger.info("Attempting without memory...")
                        
                        try:
                            # Tentar executar sem mem√≥ria
                            result = st.session_state.agent_executor.invoke(
                                {"input": prompt, "chat_history": []},
                                {"callbacks": [callback_handler]}
                            )
                        except Exception as e2:
                            # Se ainda falhar, usar modo offline
                            logger.error(f"All attempts failed: {e2}")
                            st.error("‚ùå LLM indispon√≠vel. Usando modo offline...")
                            
                            from agents.offline_agent import offline_agent
                            result = offline_agent.invoke({"input": prompt})
                
                # Armazenar an√°lise no hist√≥rico
                tools_used = [step[0].tool if hasattr(step[0], 'tool') else 'unknown' 
                            for step in result.get('intermediate_steps', [])]
                save_to_history(prompt, result.get('output', ''), tools_used)
                
                # Restaurar stdout
                verbose_output = sys.stdout.getvalue()
                sys.stdout = old_stdout
                
                # Limpar status
                status_placeholder.empty()
                progress_placeholder.empty()
                
                logger.info("Agent processing completed successfully")
                
                # Processar o resultado
                with result_container:
                    output = result.get("output", "")
                    
                    # Log intermediate steps
                    if "intermediate_steps" in result:
                        num_steps = len(result['intermediate_steps'])
                        logger.info(f"Number of intermediate steps: {num_steps}")
                        
                        # ‚ö†Ô∏è ALERTA: Se o agente n√£o usou ferramentas, avisar o usu√°rio
                        if num_steps == 0:
                            logger.warning("Agent did not use any tools - response may not be based on actual data!")
                            st.warning("‚ö†Ô∏è **ATEN√á√ÉO**: O agente respondeu sem consultar os dados. A resposta pode n√£o estar baseada no arquivo carregado. Tente reformular sua pergunta de forma mais espec√≠fica (ex: 'Analise os dados e mostre as estat√≠sticas' ou 'Quais colunas existem no dataset?')")
                    
                    # Verificar se o resultado cont√©m uma figura
                    if isinstance(output, go.Figure):
                        st.plotly_chart(output, use_container_width=True)
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "figure": output
                        })
                    else:
                        # Verificar se alguma ferramenta retornou uma figura
                        figure_found = False
                        if "intermediate_steps" in result:
                            for step in result["intermediate_steps"]:
                                if len(step) > 1 and isinstance(step[1], go.Figure):
                                    st.plotly_chart(step[1], use_container_width=True)
                                    st.session_state.messages.append({
                                        "role": "assistant",
                                        "figure": step[1]
                                    })
                                    figure_found = True
                                    break
                        
                        # Exibir texto de resposta com cabe√ßalho do modelo
                        if output:
                            # Obter informa√ß√µes do modelo atual
                            from utils.llm_fallback import llm_fallback_manager
                            provider_info = llm_fallback_manager.get_current_provider_info()
                            
                            # Criar cabe√ßalho com informa√ß√µes do modelo
                            model_header = f"""
                            ---
                            **ü§ñ Resposta gerada por:** {provider_info['name']}  
                            **üìã Modelo:** `{provider_info['model']}`  
                            **üí∞ Tipo:** {'Gratuito' if provider_info.get('is_free') else 'Pago'}  
                            **‚è±Ô∏è Rate Limit:** {provider_info.get('rate_limit', 'N/A')} req/dia
                            ---
                            """
                            
                            # Exibir cabe√ßalho e resposta
                            st.markdown(model_header)
                            st.write(output)
                            
                            if not figure_found:
                                # Incluir cabe√ßalho na mensagem salva
                                full_response = model_header + "\n\n" + output
                                st.session_state.messages.append({
                                    "role": "assistant",
                                    "content": full_response
                                })
                
                # Atualizar hist√≥rico do chat
                st.session_state.chat_history.append(HumanMessage(content=prompt))
                st.session_state.chat_history.append(AIMessage(content=str(output)))
                
                # Mostrar detalhes do processamento
                with st.expander("üîç Detalhes do Processamento"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**üìù Log do Agente:**")
                        if verbose_output:
                            st.code(verbose_output, language="text")
                    
                    with col2:
                        st.markdown("**üîß Ferramentas Utilizadas:**")
                        if "intermediate_steps" in result:
                            for i, step in enumerate(result["intermediate_steps"], 1):
                                if hasattr(step[0], 'tool'):
                                    st.write(f"{i}. {step[0].tool}")
                
            except Exception as e:
                status_placeholder.empty()
                progress_placeholder.empty()
                
                logger.error(f"Error processing question: {e}")
                logger.error(traceback.format_exc())
                
                st.error(f"‚ùå Erro ao processar pergunta: {str(e)}")
                
                with st.expander("üêõ Detalhes t√©cnicos do erro"):
                    st.code(traceback.format_exc())
                    
                    # Mostrar informa√ß√µes de debug
                    st.markdown("**Informa√ß√µes de Debug:**")
                    st.write(f"- Pergunta: {prompt}")
                    st.write(f"- DataFrame carregado: {'Sim' if st.session_state.df is not None else 'N√£o'}")
                    st.write(f"- Agente configurado: {'Sim' if st.session_state.agent_executor is not None else 'N√£o'}")
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"Desculpe, ocorreu um erro ao processar sua pergunta. Por favor, verifique os detalhes acima."
                })


def render_suggestions():
    """Renderiza sugest√µes de perguntas organizadas por categoria."""
    with st.expander("üí° Sugest√µes de Perguntas", expanded=False):
        
        # NOVO: Se√ß√£o de primeiros passos
        st.markdown("### üöÄ **Come√ßando - Use Estas Perguntas Primeiro!**")
        st.info("""
        **Para garantir que o agente consulte seus dados:**
        
        ‚úÖ "Analise os dados e me d√™ uma vis√£o geral completa"  
        ‚úÖ "Quais colunas existem no dataset?"  
        ‚úÖ "Mostre as estat√≠sticas descritivas de todas as colunas"  
        ‚úÖ "Analise os dados e identifique os principais padr√µes"  
        
        ‚ö†Ô∏è **Evite perguntas muito gen√©ricas** como "monte um plano" sem primeiro pedir para analisar os dados!
        """)
        
        st.markdown("---")
        
        # Primeira linha - Descri√ß√£o dos Dados
        st.markdown("### üìã **Descri√ß√£o dos Dados**")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **Tipos e Estrutura:**
            - "Analise os dados e mostre os tipos de cada coluna"
            - "Me d√™ uma vis√£o geral detalhada dos dados"
            - "Mostre a distribui√ß√£o de cada vari√°vel"
            - "Crie histogramas das vari√°veis num√©ricas"
            """)
        
        with col2:
            st.markdown("""
            **Medidas Estat√≠sticas:**
            - "Calcule estat√≠sticas descritivas para todas as colunas"
            - "Qual o intervalo (m√≠nimo e m√°ximo) de cada vari√°vel?"
            - "Mostre m√©dia, mediana e desvio padr√£o dos dados"
            - "Analise a variabilidade dos dados"
            """)
        
        st.markdown("---")
        
        # Segunda linha - Padr√µes e Anomalias
        st.markdown("### üîç **Identifica√ß√£o de Padr√µes e Anomalias**")
        col3, col4 = st.columns(2)
        
        with col3:
            st.markdown("""
            **Padr√µes e Tend√™ncias:**
            - "Existem padr√µes ou tend√™ncias temporais?"
            - "Quais os valores mais frequentes ou menos frequentes?"
            - "Existem agrupamentos (clusters) nos dados?"
            - "Identifique padr√µes nos dados"
            """)
        
        with col4:
            st.markdown("""
            **Detec√ß√£o de Outliers:**
            - "Existem valores at√≠picos nos dados?"
            - "Como esses outliers afetam a an√°lise?"
            - "Crie um boxplot para identificar outliers"
            - "Mostre boxplots de todas as colunas"
            """)
        
        st.markdown("---")
        
        # Terceira linha - Rela√ß√µes e Conclus√µes
        st.markdown("### üîó **Rela√ß√µes entre Vari√°veis**")
        col5, col6 = st.columns(2)
        
        with col5:
            st.markdown("""
            **An√°lise de Correla√ß√µes:**
            - "Como as vari√°veis est√£o relacionadas?"
            - "Existe correla√ß√£o entre as vari√°veis?"
            - "Mostre a matriz de correla√ß√£o"
            - "Fa√ßa gr√°ficos de dispers√£o"
            - "Quais vari√°veis t√™m maior influ√™ncia?"
            """)
        
        with col6:
            st.markdown("""
            **Insights e Conclus√µes:**
            - "Quais s√£o suas conclus√µes sobre os dados?"
            - "Que insights voc√™ pode gerar?"
            - "O que voc√™ descobriu at√© agora?"
            - "Resuma as an√°lises realizadas"
            - "Que recomenda√ß√µes voc√™ faria?"
            """)
        
        # Adicionar exemplos pr√°ticos
        st.markdown("---")
        st.markdown("### üí¨ **Exemplos de Perguntas Compostas**")
        st.info("""
        **An√°lise Completa:**
        "Fa√ßa uma an√°lise completa dos dados incluindo estat√≠sticas, distribui√ß√µes, outliers e correla√ß√µes"
        
        **An√°lise Espec√≠fica:**
        "Analise a vari√°vel 'Amount' mostrando sua distribui√ß√£o, outliers e correla√ß√£o com outras vari√°veis"
        
        **Investiga√ß√£o de Anomalias:**
        "Identifique e analise os outliers em todas as vari√°veis num√©ricas e sugira tratamento"
        """)


def render_history():
    """Renderiza o hist√≥rico de an√°lises."""
    if 'analysis_history' in st.session_state and len(st.session_state.analysis_history) > 0:
        with st.expander(f"üìú Hist√≥rico de An√°lises ({len(st.session_state.analysis_history)} an√°lises)"):
            for i, analysis in enumerate(reversed(st.session_state.analysis_history[-5:]), 1):
                st.markdown(f"**An√°lise {i}:**")
                # Verificar se 'query' existe no dicion√°rio (compatibilidade)
                query_text = analysis.get('query', analysis.get('input', 'Pergunta n√£o registrada'))
                if query_text and len(query_text) > 100:
                    st.write(f"- Pergunta: {query_text[:100]}...")
                else:
                    st.write(f"- Pergunta: {query_text}")
                    
                if analysis.get('tools_used'):
                    tools = analysis.get('tools_used', [])
                    if tools:
                        st.write(f"- Ferramentas: {', '.join(str(tool) for tool in tools)}")
                
                timestamp = analysis.get('timestamp', 'N√£o registrado')
                st.write(f"- Timestamp: {timestamp}")
                st.markdown("---")
