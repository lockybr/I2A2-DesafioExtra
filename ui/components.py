"""
Componentes da interface do usuÃ¡rio.
"""

import streamlit as st
import pandas as pd
import logging
import traceback
from datetime import datetime

from agents import create_eda_agent

logger = logging.getLogger(__name__)


def initialize_session_state():
    """Inicializa as variÃ¡veis de estado da sessÃ£o."""
    if 'df' not in st.session_state:
        st.session_state.df = None
        logger.info("Initialized df in session_state")
    if 'agent_executor' not in st.session_state:
        st.session_state.agent_executor = None
        logger.info("Initialized agent_executor in session_state")
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
        logger.info("Initialized chat_history in session_state")
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        logger.info("Initialized messages in session_state")
    if 'processing_steps' not in st.session_state:
        st.session_state.processing_steps = []
        logger.info("Initialized processing_steps in session_state")
    if 'analysis_history' not in st.session_state:
        st.session_state.analysis_history = []
        logger.info("Initialized analysis_history in session_state")
    if 'agent_memory' not in st.session_state:
        st.session_state.agent_memory = None
        logger.info("Initialized agent_memory in session_state")


def render_sidebar():
    """Renderiza a barra lateral com upload de arquivo e informaÃ§Ãµes."""
    with st.sidebar:
        st.header("ðŸ“ ConfiguraÃ§Ã£o de Dados")
        
        # Upload de arquivo
        uploaded_file = st.file_uploader(
            "Selecione um arquivo CSV",
            type=['csv'],
            help="FaÃ§a upload de um arquivo CSV para comeÃ§ar a anÃ¡lise"
        )
        
        # Seletor de LLM
        st.header("ðŸ¤– SeleÃ§Ã£o de Modelo")
        
        from config.settings_alternatives import alternative_settings
        
        # Obter lista de modelos gratuitos
        free_models = []
        model_info = {}
        
        for i, provider in enumerate(alternative_settings.get_fallback_configs()):
            if provider.get('is_free', False):
                display_name = f"{provider['name']}"
                if provider.get('rate_limit'):
                    display_name += f" ({provider['rate_limit']} req/dia)"
                else:
                    display_name += " (Ilimitado)"
                    
                free_models.append(display_name)
                model_info[display_name] = {
                    'index': i,
                    'name': provider['name'],
                    'model': provider['config']['model_name'],
                    'rate_limit': provider.get('rate_limit'),
                    'context': provider.get('context_length', 'N/A')
                }
        
        # Adicionar opÃ§Ã£o de fallback automÃ¡tico
        free_models.insert(0, "ðŸ”„ Fallback AutomÃ¡tico (Recomendado)")
        model_info["ðŸ”„ Fallback AutomÃ¡tico (Recomendado)"] = {
            'index': None,
            'name': 'Fallback AutomÃ¡tico',
            'model': 'MÃºltiplos modelos',
            'rate_limit': 'VariÃ¡vel'
        }
        
        selected_model = st.selectbox(
            "Escolha o modelo LLM:",
            options=free_models,
            index=0,
            help="Selecione qual modelo usar para anÃ¡lise. O fallback automÃ¡tico tentarÃ¡ vÃ¡rios modelos em ordem de prioridade."
        )
        
        # Mostrar informaÃ§Ãµes do modelo selecionado
        if selected_model in model_info:
            info = model_info[selected_model]
            with st.expander("â„¹ï¸ InformaÃ§Ãµes do Modelo", expanded=False):
                st.write(f"**Nome:** {info['name']}")
                st.write(f"**Modelo:** `{info['model']}`")
                st.write(f"**Rate Limit:** {info['rate_limit']}")
                if info.get('context'):
                    st.write(f"**Contexto:** {info['context']}")
        
        # Armazenar seleÃ§Ã£o no session_state
        st.session_state.selected_model_index = model_info[selected_model]['index']
        
        # BotÃ£o para aplicar mudanÃ§a de modelo
        if st.button("ðŸ”„ Aplicar Modelo Selecionado", help="Reconfigura o agente com o modelo selecionado"):
            # ForÃ§ar recriaÃ§Ã£o do agente
            st.session_state.agent_executor = None
            if hasattr(st.session_state, 'current_model_index'):
                del st.session_state.current_model_index
            st.rerun()
        
        if uploaded_file is not None:
            try:
                # Mostrar status de carregamento
                status_container = st.container()
                with status_container:
                    with st.spinner("ðŸ“‚ Carregando arquivo..."):
                        logger.info(f"Loading file: {uploaded_file.name}")
                        df = pd.read_csv(uploaded_file)
                        st.session_state.df = df
                        logger.info(f"File loaded successfully: {df.shape}")
                    
                    st.success(f"âœ… Arquivo carregado: {df.shape[0]:,} linhas Ã— {df.shape[1]} colunas")
                
                # Verificar se precisa recriar o agente (modelo mudou ou nÃ£o existe)
                need_recreate = (
                    st.session_state.agent_executor is None or
                    not hasattr(st.session_state, 'current_model_index') or
                    st.session_state.current_model_index != st.session_state.selected_model_index
                )
                
                if need_recreate:
                    with status_container:
                        with st.spinner("ðŸ”§ Configurando agente de anÃ¡lise..."):
                            # IMPORTANTE: Garantir que o DataFrame estÃ¡ disponÃ­vel antes de criar o agente
                            logger.info(f"Creating agent with DataFrame shape: {st.session_state.df.shape}")
                            
                            # Mostrar qual modelo serÃ¡ usado
                            if st.session_state.selected_model_index is not None:
                                from config.settings_alternatives import alternative_settings
                                selected_provider = alternative_settings.get_fallback_configs()[st.session_state.selected_model_index]
                                st.info(f"ðŸŽ¯ Configurando com {selected_provider['name']}...")
                            else:
                                st.info("ðŸ”„ Configurando com fallback automÃ¡tico...")
                            
                            # Recriar o agente (o DataFrame jÃ¡ estÃ¡ em st.session_state.df)
                            st.session_state.agent_executor = create_eda_agent()
                            
                            # Armazenar o Ã­ndice do modelo atual
                            st.session_state.current_model_index = st.session_state.selected_model_index
                            
                            # Verificar se o DataFrame ainda estÃ¡ disponÃ­vel apÃ³s criar o agente
                            if st.session_state.df is not None:
                                logger.info(f"DataFrame verified after agent creation: {st.session_state.df.shape}")
                            else:
                                logger.error("DataFrame was lost after agent creation!")
                            
                            # Mostrar qual modelo foi realmente usado
                            from utils.llm_fallback import llm_fallback_manager
                            provider_info = llm_fallback_manager.get_current_provider_info()
                            if provider_info['name'] != 'Nenhum':
                                st.success(f"âœ… Agente configurado com {provider_info['name']}!")
                            else:
                                st.success("âœ… Agente configurado com sucesso!")
                            logger.info(f"Agent configured and ready with model index: {st.session_state.selected_model_index}")
                
                # Mostrar informaÃ§Ãµes bÃ¡sicas
                st.markdown("### ðŸ“Š Dataset Carregado")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Total de Linhas", f"{df.shape[0]:,}")
                with col2:
                    st.metric("Total de Colunas", df.shape[1])
                
                # Preview dos dados
                with st.expander("ðŸ‘€ Preview dos Dados", expanded=True):
                    tab1, tab2, tab3 = st.tabs(["Primeiras linhas", "Ãšltimas linhas", "Amostra aleatÃ³ria"])
                    with tab1:
                        st.dataframe(df.head(10))
                    with tab2:
                        st.dataframe(df.tail(10))
                    with tab3:
                        st.dataframe(df.sample(min(10, len(df))))
                
                # Mostrar colunas disponÃ­veis
                with st.expander("ðŸ“‹ Colunas DisponÃ­veis"):
                    cols_info = pd.DataFrame({
                        'Coluna': df.columns,
                        'Tipo': df.dtypes.astype(str),
                        'NÃ£o-Nulos': df.count()
                    })
                    st.dataframe(cols_info)
                
                # Mostrar status do modelo atual
                st.markdown("### ðŸ¤– Status do Modelo")
                if st.session_state.agent_executor is not None:
                    from utils.llm_fallback import llm_fallback_manager
                    provider_info = llm_fallback_manager.get_current_provider_info()
                    
                    if provider_info['name'] != 'Nenhum':
                        st.info(f"**Modelo Ativo:** {provider_info['name']}")
                        st.caption(f"ðŸ“‹ {provider_info['model']}")
                        st.caption(f"ðŸ’° {'Gratuito' if provider_info.get('is_free') else 'Pago'}")
                        if provider_info.get('rate_limit'):
                            st.caption(f"â±ï¸ {provider_info['rate_limit']} req/dia")
                        
                        # Mostrar se estÃ¡ usando modelo selecionado ou fallback
                        if st.session_state.selected_model_index is not None:
                            st.caption("ðŸŽ¯ Modelo selecionado manualmente")
                        else:
                            st.caption("ðŸ”„ Fallback automÃ¡tico ativo")
                    else:
                        st.warning("âš ï¸ Nenhum modelo ativo")
                else:
                    st.warning("âš ï¸ Agente nÃ£o configurado")
                    
            except Exception as e:
                logger.error(f"Error loading file: {e}")
                logger.error(traceback.format_exc())
                st.error(f"âŒ Erro ao carregar arquivo: {str(e)}")
                with st.expander("ðŸ” Detalhes do erro"):
                    st.code(traceback.format_exc())
                st.session_state.df = None
                st.session_state.agent_executor = None
        
        # BotÃ£o para limpar sessÃ£o
        if st.button("ðŸ”„ Nova AnÃ¡lise"):
            logger.info("Clearing session state")
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()


def render_chat_interface():
    """Renderiza a interface de chat principal."""
    if st.session_state.df is not None and st.session_state.agent_executor is not None:
        
        # Container para mensagens do chat
        st.subheader("ðŸ’¬ Chat de AnÃ¡lise")
        
        # Exibir histÃ³rico de mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if message["role"] == "user":
                    st.write(message["content"])
                else:
                    # Para mensagens do assistente, verificar se hÃ¡ figuras
                    if "figure" in message:
                        st.plotly_chart(message["figure"], use_container_width=True)
                    else:
                        st.write(message["content"])
        
        # Input do usuÃ¡rio
        if prompt := st.chat_input("Digite sua pergunta sobre os dados..."):
            # Adicionar mensagem do usuÃ¡rio
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)
            
            # Processar com o agente
            _process_user_query(prompt)
    else:
        # Mensagem quando nÃ£o hÃ¡ dados carregados
        st.info("ðŸ‘ˆ Por favor, faÃ§a upload de um arquivo CSV na barra lateral para comeÃ§ar a anÃ¡lise.")


def _process_user_query(prompt: str):
    """Processa a pergunta do usuÃ¡rio com o agente."""
    import io
    import sys
    import plotly.graph_objects as go
    from langchain_core.messages import HumanMessage, AIMessage
    from utils.callbacks import StreamlitCallbackHandler
    from utils.memory import save_to_history
    
    with st.chat_message("assistant"):
        # Container para mostrar progresso
        progress_container = st.container()
        result_container = st.container()
        
        with progress_container:
            status_placeholder = st.empty()
            progress_placeholder = st.empty()
            
            try:
                # Criar callback handler
                callback_handler = StreamlitCallbackHandler(progress_placeholder)
                
                # Status inicial
                status_placeholder.info("ðŸ” Processando sua pergunta...")
                logger.info(f"Processing user input: {prompt}")
                
                # Redirecionar stdout temporariamente para capturar prints
                old_stdout = sys.stdout
                sys.stdout = io.StringIO()
                
                # Executar o agente com callbacks
                try:
                    result = st.session_state.agent_executor.invoke(
                        {"input": prompt},
                        {"callbacks": [callback_handler]}
                    )
                except (NotImplementedError, Exception) as nie:
                    # Verificar se Ã© erro de rate limit
                    if "429" in str(nie) or "rate limit" in str(nie).lower():
                        logger.warning(f"Rate limit detected: {nie}")
                        st.error("âš ï¸ Limite de requisiÃ§Ãµes excedido. Mudando para modo offline...")
                        
                        # Usar agente offline
                        from agents.offline_agent import offline_agent
                        result = offline_agent.invoke({"input": prompt})
                        
                    else:
                        # Outros erros - tentar sem memÃ³ria
                        logger.warning(f"Memory issue detected: {nie}")
                        logger.info("Attempting without memory...")
                        
                        try:
                            # Tentar executar sem memÃ³ria
                            result = st.session_state.agent_executor.invoke(
                                {"input": prompt, "chat_history": []},
                                {"callbacks": [callback_handler]}
                            )
                        except Exception as e2:
                            # Se ainda falhar, usar modo offline
                            logger.error(f"All attempts failed: {e2}")
                            st.error("âŒ LLM indisponÃ­vel. Usando modo offline...")
                            
                            from agents.offline_agent import offline_agent
                            result = offline_agent.invoke({"input": prompt})
                
                # Armazenar anÃ¡lise no histÃ³rico
                tools_used = [step[0].tool if hasattr(step[0], 'tool') else 'unknown' 
                            for step in result.get('intermediate_steps', [])]
                save_to_history(prompt, result.get('output', ''), tools_used)
                
                # Restaurar stdout
                verbose_output = sys.stdout.getvalue()
                sys.stdout = old_stdout
                
                # Limpar status
                status_placeholder.empty()
                progress_placeholder.empty()
                
                logger.info("Agent processing completed successfully")
                
                # Processar o resultado
                with result_container:
                    output = result.get("output", "")
                    
                    # Log intermediate steps
                    if "intermediate_steps" in result:
                        num_steps = len(result['intermediate_steps'])
                        logger.info(f"Number of intermediate steps: {num_steps}")
                        
                        # âš ï¸ ALERTA: Se o agente nÃ£o usou ferramentas, avisar o usuÃ¡rio
                        if num_steps == 0:
                            logger.warning("Agent did not use any tools - response may not be based on actual data!")
                            st.warning("âš ï¸ **ATENÃ‡ÃƒO**: O agente respondeu sem consultar os dados. A resposta pode nÃ£o estar baseada no arquivo carregado. Tente reformular sua pergunta de forma mais especÃ­fica (ex: 'Analise os dados e mostre as estatÃ­sticas' ou 'Quais colunas existem no dataset?')")
                    
                    # Verificar se o resultado contÃ©m uma figura
                    if isinstance(output, go.Figure):
                        st.plotly_chart(output, use_container_width=True)
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "figure": output
                        })
                    else:
                        # Verificar se alguma ferramenta retornou uma figura
                        figure_found = False
                        if "intermediate_steps" in result:
                            for step in result["intermediate_steps"]:
                                if len(step) > 1 and isinstance(step[1], go.Figure):
                                    st.plotly_chart(step[1], use_container_width=True)
                                    st.session_state.messages.append({
                                        "role": "assistant",
                                        "figure": step[1]
                                    })
                                    figure_found = True
                                    break
                        
                        # Exibir texto de resposta com cabeÃ§alho do modelo
                        if output:
                            # Obter informaÃ§Ãµes do modelo atual
                            from utils.llm_fallback import llm_fallback_manager
                            provider_info = llm_fallback_manager.get_current_provider_info()
                            
                            # Criar cabeÃ§alho com informaÃ§Ãµes do modelo
                            model_header = f"""
                            ---
                            **ðŸ¤– Resposta gerada por:** {provider_info['name']}  
                            **ðŸ“‹ Modelo:** `{provider_info['model']}`  
                            **ðŸ’° Tipo:** {'Gratuito' if provider_info.get('is_free') else 'Pago'}  
                            **â±ï¸ Rate Limit:** {provider_info.get('rate_limit', 'N/A')} req/dia
                            ---
                            """
                            
                            # Exibir cabeÃ§alho e resposta
                            st.markdown(model_header)
                            st.write(output)
                            
                            if not figure_found:
                                # Incluir cabeÃ§alho na mensagem salva
                                full_response = model_header + "\n\n" + output
                                st.session_state.messages.append({
                                    "role": "assistant",
                                    "content": full_response
                                })
                
                # Atualizar histÃ³rico do chat
                st.session_state.chat_history.append(HumanMessage(content=prompt))
                st.session_state.chat_history.append(AIMessage(content=str(output)))
                
                # Mostrar detalhes do processamento
                with st.expander("ðŸ” Detalhes do Processamento"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ðŸ“ Log do Agente:**")
                        if verbose_output:
                            st.code(verbose_output, language="text")
                    
                    with col2:
                        st.markdown("**ðŸ”§ Ferramentas Utilizadas:**")
                        if "intermediate_steps" in result:
                            for i, step in enumerate(result["intermediate_steps"], 1):
                                if hasattr(step[0], 'tool'):
                                    st.write(f"{i}. {step[0].tool}")
                
            except Exception as e:
                status_placeholder.empty()
                progress_placeholder.empty()
                
                logger.error(f"Error processing question: {e}")
                logger.error(traceback.format_exc())
                
                st.error(f"âŒ Erro ao processar pergunta: {str(e)}")
                
                with st.expander("ðŸ› Detalhes tÃ©cnicos do erro"):
                    st.code(traceback.format_exc())
                    
                    # Mostrar informaÃ§Ãµes de debug
                    st.markdown("**InformaÃ§Ãµes de Debug:**")
                    st.write(f"- Pergunta: {prompt}")
                    st.write(f"- DataFrame carregado: {'Sim' if st.session_state.df is not None else 'NÃ£o'}")
                    st.write(f"- Agente configurado: {'Sim' if st.session_state.agent_executor is not None else 'NÃ£o'}")
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"Desculpe, ocorreu um erro ao processar sua pergunta. Por favor, verifique os detalhes acima."
                })


def render_suggestions():
    """Renderiza sugestÃµes de perguntas organizadas por categoria."""
    with st.expander("ðŸ’¡ SugestÃµes de Perguntas", expanded=False):
        
        # NOVO: SeÃ§Ã£o de primeiros passos
        st.markdown("### ðŸš€ **ComeÃ§ando - Use Estas Perguntas Primeiro!**")
        st.info("""
        **Para garantir que o agente consulte seus dados:**
        
        âœ… "Analise os dados e me dÃª uma visÃ£o geral completa"  
        âœ… "Quais colunas existem no dataset?"  
        âœ… "Mostre as estatÃ­sticas descritivas de todas as colunas"  
        âœ… "Analise os dados e identifique os principais padrÃµes"  
        
        âš ï¸ **Evite perguntas muito genÃ©ricas** como "monte um plano" sem primeiro pedir para analisar os dados!
        """)
        
        st.markdown("---")
        
        # Primeira linha - DescriÃ§Ã£o dos Dados
        st.markdown("### ðŸ“‹ **DescriÃ§Ã£o dos Dados**")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **Tipos e Estrutura:**
            - "Analise os dados e mostre os tipos de cada coluna"
            - "Me dÃª uma visÃ£o geral detalhada dos dados"
            - "Mostre a distribuiÃ§Ã£o de cada variÃ¡vel"
            - "Crie histogramas das variÃ¡veis numÃ©ricas"
            """)
        
        with col2:
            st.markdown("""
            **Medidas EstatÃ­sticas:**
            - "Calcule estatÃ­sticas descritivas para todas as colunas"
            - "Qual o intervalo (mÃ­nimo e mÃ¡ximo) de cada variÃ¡vel?"
            - "Mostre mÃ©dia, mediana e desvio padrÃ£o dos dados"
            - "Analise a variabilidade dos dados"
            """)
        
        st.markdown("---")
        
        # Segunda linha - PadrÃµes e Anomalias
        st.markdown("### ðŸ” **IdentificaÃ§Ã£o de PadrÃµes e Anomalias**")
        col3, col4 = st.columns(2)
        
        with col3:
            st.markdown("""
            **PadrÃµes e TendÃªncias:**
            - "Existem padrÃµes ou tendÃªncias temporais?"
            - "Quais os valores mais frequentes ou menos frequentes?"
            - "Existem agrupamentos (clusters) nos dados?"
            - "Identifique padrÃµes nos dados"
            """)
        
        with col4:
            st.markdown("""
            **DetecÃ§Ã£o de Outliers:**
            - "Existem valores atÃ­picos nos dados?"
            - "Como esses outliers afetam a anÃ¡lise?"
            - "Crie um boxplot para identificar outliers"
            - "Mostre boxplots de todas as colunas"
            """)
        
        st.markdown("---")
        
        # Terceira linha - RelaÃ§Ãµes e ConclusÃµes
        st.markdown("### ðŸ”— **RelaÃ§Ãµes entre VariÃ¡veis**")
        col5, col6 = st.columns(2)
        
        with col5:
            st.markdown("""
            **AnÃ¡lise de CorrelaÃ§Ãµes:**
            - "Como as variÃ¡veis estÃ£o relacionadas?"
            - "Existe correlaÃ§Ã£o entre as variÃ¡veis?"
            - "Mostre a matriz de correlaÃ§Ã£o"
            - "FaÃ§a grÃ¡ficos de dispersÃ£o"
            - "Quais variÃ¡veis tÃªm maior influÃªncia?"
            """)
        
        with col6:
            st.markdown("""
            **Insights e ConclusÃµes:**
            - "Quais sÃ£o suas conclusÃµes sobre os dados?"
            - "Que insights vocÃª pode gerar?"
            - "O que vocÃª descobriu atÃ© agora?"
            - "Resuma as anÃ¡lises realizadas"
            - "Que recomendaÃ§Ãµes vocÃª faria?"
            """)
        
        # Adicionar exemplos prÃ¡ticos
        st.markdown("---")
        st.markdown("### ðŸ’¬ **Exemplos de Perguntas Compostas**")
        st.info("""
        **AnÃ¡lise Completa:**
        "FaÃ§a uma anÃ¡lise completa dos dados incluindo estatÃ­sticas, distribuiÃ§Ãµes, outliers e correlaÃ§Ãµes"
        
        **AnÃ¡lise EspecÃ­fica:**
        "Analise a variÃ¡vel 'Amount' mostrando sua distribuiÃ§Ã£o, outliers e correlaÃ§Ã£o com outras variÃ¡veis"
        
        **InvestigaÃ§Ã£o de Anomalias:**
        "Identifique e analise os outliers em todas as variÃ¡veis numÃ©ricas e sugira tratamento"
        """)


def render_history():
    """Renderiza o histÃ³rico de anÃ¡lises."""
    if 'analysis_history' in st.session_state and len(st.session_state.analysis_history) > 0:
        with st.expander(f"ðŸ“œ HistÃ³rico de AnÃ¡lises ({len(st.session_state.analysis_history)} anÃ¡lises)"):
            for i, analysis in enumerate(reversed(st.session_state.analysis_history[-5:]), 1):
                st.markdown(f"**AnÃ¡lise {i}:**")
                # Verificar se 'query' existe no dicionÃ¡rio (compatibilidade)
                query_text = analysis.get('query', analysis.get('input', 'Pergunta nÃ£o registrada'))
                if query_text and len(query_text) > 100:
                    st.write(f"- Pergunta: {query_text[:100]}...")
                else:
                    st.write(f"- Pergunta: {query_text}")
                    
                if analysis.get('tools_used'):
                    tools = analysis.get('tools_used', [])
                    if tools:
                        st.write(f"- Ferramentas: {', '.join(str(tool) for tool in tools)}")
                
                timestamp = analysis.get('timestamp', 'NÃ£o registrado')
                st.write(f"- Timestamp: {timestamp}")
                st.markdown("---")
