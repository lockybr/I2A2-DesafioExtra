"""
Ferramenta de gera√ß√£o de insights e conclus√µes para o EDA Agent.
"""

import streamlit as st
import pandas as pd
import numpy as np
import logging
from datetime import datetime
from langchain.tools import tool

logger = logging.getLogger(__name__)

@tool
def generate_insights_and_conclusions() -> str:
    """
    Analisa todos os resultados anteriores e gera insights e conclus√µes 
    baseados nas an√°lises j√° realizadas durante a sess√£o.
    """
    logger.info("Generating insights and conclusions")
    logger.info(f"Session state has 'df': {'df' in st.session_state}")
    logger.info(f"Session state has 'analysis_history': {'analysis_history' in st.session_state}")
    
    if 'analysis_history' not in st.session_state:
        return "‚ö†Ô∏è Ainda n√£o foram realizadas an√°lises suficientes para gerar conclus√µes."
    
    if 'df' not in st.session_state:
        logger.error("'df' key not found in session_state")
        return "‚ùå Erro: Nenhum dado foi carregado ainda. Por favor, fa√ßa upload de um arquivo CSV."
    
    if st.session_state.df is None:
        logger.error("DataFrame is None in session_state")
        return "‚ùå Erro: O DataFrame est√° vazio. Por favor, fa√ßa upload de um arquivo CSV."
    
    df = st.session_state.df
    logger.info(f"‚úÖ Successfully accessed DataFrame with shape: {df.shape}")
    history = st.session_state.analysis_history
    
    insights = []
    insights.append("## üéØ Insights e Conclus√µes Baseados nas An√°lises\n")
    
    # An√°lise do dataset
    insights.append(f"### üìä Caracter√≠sticas do Dataset:")
    insights.append(f"- **Volume de dados**: {df.shape[0]:,} registros com {df.shape[1]} vari√°veis")
    
    # An√°lise de tipos de dados
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    categorical_cols = df.select_dtypes(exclude=[np.number]).columns
    insights.append(f"- **Vari√°veis num√©ricas**: {len(numeric_cols)} colunas")
    insights.append(f"- **Vari√°veis categ√≥ricas**: {len(categorical_cols)} colunas")
    
    # An√°lise de valores faltantes
    missing_data = df.isnull().sum()
    if missing_data.sum() > 0:
        insights.append(f"\n### ‚ö†Ô∏è Dados Faltantes:")
        for col in missing_data[missing_data > 0].index:
            pct = (missing_data[col] / len(df)) * 100
            insights.append(f"- **{col}**: {missing_data[col]:,} valores ({pct:.2f}%)")
    else:
        insights.append(f"\n### ‚úÖ **Qualidade dos Dados**: N√£o h√° valores faltantes")
    
    # An√°lise estat√≠stica
    if len(numeric_cols) > 0:
        insights.append(f"\n### üìà Insights Estat√≠sticos:")
        
        for col in numeric_cols[:5]:  # Limitar a 5 colunas mais importantes
            mean_val = df[col].mean()
            std_val = df[col].std()
            cv = (std_val / mean_val * 100) if mean_val != 0 else 0
            skew = df[col].skew()
            
            insights.append(f"\n**{col}:**")
            insights.append(f"- M√©dia: {mean_val:.2f}, Desvio: {std_val:.2f}")
            
            if cv > 100:
                insights.append(f"- ‚ö†Ô∏è Alta variabilidade (CV: {cv:.1f}%)")
            elif cv > 50:
                insights.append(f"- Variabilidade moderada (CV: {cv:.1f}%)")
            else:
                insights.append(f"- Baixa variabilidade (CV: {cv:.1f}%)")
            
            if abs(skew) > 1:
                direction = "positiva" if skew > 0 else "negativa"
                insights.append(f"- Distribui√ß√£o com forte assimetria {direction}")
    
    # An√°lise de correla√ß√µes
    if len(numeric_cols) > 1:
        corr_matrix = df[numeric_cols].corr()
        high_corr = []
        
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:
                    high_corr.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))
        
        if high_corr:
            insights.append(f"\n### üîó Correla√ß√µes Importantes:")
            for col1, col2, corr in high_corr[:5]:  # Limitar a 5 correla√ß√µes
                if corr > 0:
                    insights.append(f"- **{col1}** e **{col2}**: Forte correla√ß√£o positiva ({corr:.2f})")
                else:
                    insights.append(f"- **{col1}** e **{col2}**: Forte correla√ß√£o negativa ({corr:.2f})")
    
    # An√°lise de outliers
    outlier_info = _analyze_outliers(df, numeric_cols)
    if outlier_info:
        insights.append(f"\n### üîç An√°lise de Outliers:")
        for info in outlier_info[:5]:
            insights.append(f"- **{info['column']}**: {info['count']} outliers ({info['percentage']:.1f}% dos dados)")
    
    # Adicionar hist√≥rico de an√°lises realizadas
    if 'messages' in st.session_state and len(st.session_state.messages) > 0:
        insights.append(f"\n### üìù An√°lises Realizadas na Sess√£o:")
        analysis_count = _count_analyses(st.session_state.messages)
        
        for analysis, count in analysis_count.items():
            insights.append(f"- {analysis}: {count} an√°lise(s)")
    
    # Recomenda√ß√µes finais
    insights.append(f"\n### üí° Recomenda√ß√µes:")
    
    if len(numeric_cols) > 10:
        insights.append(f"- Dataset com muitas vari√°veis ({len(numeric_cols)}), considere an√°lise de componentes principais (PCA)")
    
    if df.shape[0] > 100000:
        insights.append(f"- Grande volume de dados ({df.shape[0]:,} registros), considere t√©cnicas de amostragem para an√°lises explorat√≥rias")
    
    if high_corr:
        insights.append(f"- Vari√°veis altamente correlacionadas detectadas, avalie multicolinearidade em modelos")
    
    if outlier_info and any(o['percentage'] > 5 for o in outlier_info):
        insights.append(f"- Presen√ßa significativa de outliers, considere t√©cnicas de tratamento ou remo√ß√£o")
    
    # Armazenar conclus√µes no hist√≥rico
    conclusion_summary = "\n".join(insights)
    
    if 'analysis_history' not in st.session_state:
        st.session_state.analysis_history = []
    
    st.session_state.analysis_history.append({
        'timestamp': datetime.now().isoformat(),
        'type': 'conclusions',
        'content': conclusion_summary
    })
    
    return conclusion_summary


def _analyze_outliers(df: pd.DataFrame, numeric_cols) -> list:
    """Analisa outliers usando m√©todo IQR."""
    outlier_info = []
    
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]
        outlier_count = len(outliers)
        
        if outlier_count > 0:
            outlier_info.append({
                'column': col,
                'count': outlier_count,
                'percentage': (outlier_count / len(df)) * 100
            })
    
    return sorted(outlier_info, key=lambda x: x['count'], reverse=True)


def _count_analyses(messages: list) -> dict:
    """Conta os tipos de an√°lises realizadas."""
    analysis_count = {}
    
    for msg in messages:
        if msg.get('role') == 'user':
            content = msg.get('content', '').lower()
            
            if 'histogram' in content or 'histograma' in content:
                analysis_count['Histogramas'] = analysis_count.get('Histogramas', 0) + 1
            elif 'boxplot' in content:
                analysis_count['Boxplots'] = analysis_count.get('Boxplots', 0) + 1
            elif 'correla√ß√£o' in content or 'correlation' in content:
                analysis_count['Correla√ß√µes'] = analysis_count.get('Correla√ß√µes', 0) + 1
            elif 'scatter' in content or 'dispers√£o' in content:
                analysis_count['Dispers√µes'] = analysis_count.get('Dispers√µes', 0) + 1
            elif 'estat√≠stica' in content or 'statistics' in content:
                analysis_count['Estat√≠sticas'] = analysis_count.get('Estat√≠sticas', 0) + 1
            elif 'vis√£o geral' in content or 'overview' in content:
                analysis_count['Vis√µes Gerais'] = analysis_count.get('Vis√µes Gerais', 0) + 1
    
    return analysis_count
