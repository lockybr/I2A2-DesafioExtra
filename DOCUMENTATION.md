# ğŸ“š DocumentaÃ§Ã£o Completa - I2A2 EDA Agent v2.0.3

## Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [CaracterÃ­sticas Principais](#caracterÃ­sticas-principais)
3. [Funcionalidades Detalhadas](#funcionalidades-detalhadas)
4. [Arquitetura da SoluÃ§Ã£o](#arquitetura-da-soluÃ§Ã£o)
5. [Tecnologias e Frameworks](#tecnologias-e-frameworks)
6. [Estrutura do Projeto](#estrutura-do-projeto)
7. [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#instalaÃ§Ã£o-e-configuraÃ§Ã£o)
8. [Modos de Uso](#modos-de-uso)
9. [Guia de Desenvolvimento](#guia-de-desenvolvimento)
10. [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
11. [Troubleshooting](#troubleshooting)
12. [ReferÃªncias e Recursos](#referÃªncias-e-recursos)

---

## VisÃ£o Geral

### O que Ã© o I2A2 EDA Agent?

O **I2A2 EDA Agent** Ã© uma aplicaÃ§Ã£o inteligente de anÃ¡lise exploratÃ³ria de dados (Exploratory Data Analysis) que combina o poder de mÃºltiplas LLMs com ferramentas estatÃ­sticas robustas. Desenvolvido com uma arquitetura modular e escalÃ¡vel, permite que analistas e cientistas de dados realizem anÃ¡lises complexas usando linguagem natural.

**Powered by Saulo Belchior** - VersÃ£o 2.0.3

### PropÃ³sito

- **Democratizar** a anÃ¡lise de dados atravÃ©s de interface conversacional
- **Automatizar** tarefas repetitivas de EDA
- **Acelerar** o processo de descoberta de insights
- **Manter contexto** entre anÃ¡lises para construÃ§Ã£o incremental de conhecimento

### Diferenciais

1. **Sistema Multi-LLM**: 3 modelos gratuitos com fallback automÃ¡tico
2. **SeleÃ§Ã£o de Modelo**: UsuÃ¡rio escolhe qual LLM usar
3. **TransparÃªncia Total**: Cada resposta mostra qual modelo foi usado
4. **Agente Inteligente com MemÃ³ria**: MantÃ©m contexto entre anÃ¡lises
5. **Modo Offline**: Funciona mesmo sem acesso a LLMs
6. **Arquitetura Modular**: FÃ¡cil manutenÃ§Ã£o e extensÃ£o
7. **Interface Intuitiva**: AnÃ¡lises complexas com comandos simples

---

## CaracterÃ­sticas Principais

### ğŸ§  InteligÃªncia Artificial

- **LangChain Framework**: OrquestraÃ§Ã£o de agentes e ferramentas
- **MemÃ³ria Conversacional**: ConversationBufferWindowMemory mantÃ©m contexto
- **Processamento de Linguagem Natural**: Entende comandos em portuguÃªs e inglÃªs
- **GeraÃ§Ã£o AutomÃ¡tica de Insights**: Sintetiza descobertas em conclusÃµes acionÃ¡veis

### ğŸ›¡ï¸ Robustez e Confiabilidade

- **Sistema Multi-LLM**: 3 modelos gratuitos (xAI Grok, Meta Llama 3.2, DeepSeek)
- **Fallback AutomÃ¡tico**: Troca de modelo em caso de falha
- **SeleÃ§Ã£o Manual**: UsuÃ¡rio pode forÃ§ar modelo especÃ­fico
- **TransparÃªncia**: Cada resposta mostra qual modelo foi usado
- **Modo Offline**: AnÃ¡lises baseadas em regras quando LLM indisponÃ­vel
- **Tratamento de Erros**: Feedback claro e opÃ§Ãµes de recuperaÃ§Ã£o

### ğŸ“Š Capacidades AnalÃ­ticas

- **7 Ferramentas Especializadas**: Cobertura completa de tÃ©cnicas EDA
- **GeraÃ§Ã£o de Insights**: Ferramenta para sintetizar conclusÃµes
- **VisualizaÃ§Ãµes Interativas**: GrÃ¡ficos Plotly com zoom e exportaÃ§Ã£o
- **AnÃ¡lise EstatÃ­stica Completa**: Medidas descritivas, correlaÃ§Ãµes, outliers
- **DetecÃ§Ã£o de PadrÃµes**: IdentificaÃ§Ã£o automÃ¡tica de anomalias e tendÃªncias

### ğŸ¨ Interface e ExperiÃªncia

- **Interface Web Moderna**: Streamlit com design responsivo
- **Chat Conversacional**: InteraÃ§Ã£o natural como conversa
- **SugestÃµes Inteligentes**: Perguntas organizadas por categoria
- **HistÃ³rico de AnÃ¡lises**: Rastreamento de todas as interaÃ§Ãµes

---

## Funcionalidades Detalhadas

### 1. Ferramentas de AnÃ¡lise

#### ğŸ“‹ **get_data_description**
```python
PropÃ³sito: VisÃ£o geral do dataset
Retorna: 
- DimensÃµes (linhas Ã— colunas)
- Tipos de dados
- Valores ausentes
- EstatÃ­sticas bÃ¡sicas
```

#### ğŸ“ˆ **get_descriptive_statistics**
```python
PropÃ³sito: EstatÃ­sticas descritivas detalhadas
ParÃ¢metros: column (opcional)
Retorna:
- Count, mean, std, min, max
- Quartis (25%, 50%, 75%)
- Skewness e Kurtosis
```

#### ğŸ“Š **plot_histogram**
```python
PropÃ³sito: Visualizar distribuiÃ§Ã£o de variÃ¡vel
ParÃ¢metros: column (obrigatÃ³rio)
Retorna: Histograma interativo Plotly
```

#### ğŸ“¦ **plot_boxplot**
```python
PropÃ³sito: Identificar outliers de uma coluna
ParÃ¢metros: column (obrigatÃ³rio)
Retorna: Boxplot com outliers destacados
```

#### ğŸ“¦ **plot_multiple_boxplots**
```python
PropÃ³sito: AnÃ¡lise de outliers de todas as colunas
ParÃ¢metros: Nenhum
Retorna: Grid de boxplots
```

#### ğŸ”— **plot_correlation_heatmap**
```python
PropÃ³sito: Matriz de correlaÃ§Ã£o entre variÃ¡veis
ParÃ¢metros: Nenhum
Retorna: Heatmap colorido com valores
```

#### ğŸ¯ **plot_scatter**
```python
PropÃ³sito: RelaÃ§Ã£o entre duas variÃ¡veis
ParÃ¢metros: x_column, y_column
Retorna: GrÃ¡fico de dispersÃ£o com linha de tendÃªncia
```

#### ğŸ’¡ **generate_insights_and_conclusions**
```python
PropÃ³sito: Sintetizar anÃ¡lises em insights
ParÃ¢metros: Nenhum
Retorna: ConclusÃµes baseadas no histÃ³rico
```

### 2. Modos de OperaÃ§Ã£o

#### Modo Normal (Com LLM)
- Processamento completo com IA
- Entendimento de contexto complexo
- GeraÃ§Ã£o de insights sofisticados
- MemÃ³ria de longo prazo

#### Modo Offline (Sem LLM)
- DetecÃ§Ã£o baseada em regras
- AnÃ¡lise por palavras-chave
- ExecuÃ§Ã£o direta de ferramentas
- Fallback inteligente
#### Modo HÃ­brido
- Tenta LLM principal
- Ãšltimo recurso: modo offline
- TransparÃªncia sobre modo usado

##  Framework escolhida: LangChain
  
  O projeto adota o LangChain como framework central para aplicaÃ§Ãµes com LLMs. Ele simplifica a orquestraÃ§Ã£o do agente, reduz boilerplate e garante consistÃªncia do histÃ³rico.
  
  - **Tools nativas (`@tool`)**: o decorador transforma funÃ§Ãµes Python em ferramentas com JSON Schema para tool-calling, usadas no mÃ³dulo `tools/`.
  - **AgentExecutor (motor do agente)**: recebe o LLM, as ferramentas e a pergunta do usuÃ¡rio, e cuida de:
    - Formatar o prompt com as ferramentas disponÃ­veis
    - Invocar o LLM e interpretar qual ferramenta e argumentos usar
    - Executar a funÃ§Ã£o Python correspondente
    - (Opcional) Enviar o resultado de volta ao LLM para resposta final em linguagem natural
    - Gerenciar a memÃ³ria e o histÃ³rico da sessÃ£o
  - **MemÃ³ria Conversacional**: integraÃ§Ã£o com `ConversationSummaryBufferMemory`/`ConversationBufferWindowMemory` preservando contexto entre interaÃ§Ãµes.
  - **IntegraÃ§Ãµes**: compatÃ­vel com mÃºltiplos provedores e modelos (via OpenRouter, OpenAI, Groq, Gemini, Ollama), reduzindo a configuraÃ§Ã£o.
  
  BenefÃ­cio no projeto: focamos na lÃ³gica das ferramentas e UX, enquanto o LangChain gerencia o ciclo agenteâ†”LLMâ†”ferramentas.

## Arquitetura da SoluÃ§Ã£o

### Diagrama de VisÃ£o Geral
   U[UsuÃ¡rio] --> UI[Streamlit UI]
   UI --> A[LangChain Agent Executor]
   A -- memÃ³ria --> M[Conversation Memory]
   T --> D[DataFrame (Pandas)]
   A -- LLM --> L[LLM Providers\n(DeepSeek/Groq/Gemini/Ollama)]
   L --> F[Fallback Manager]
   F --> O[Offline Agent]
   A --> R[Respostas/VisualizaÃ§Ãµes]
  ```
  R --> UI
  ```
 
 #### Diagrama (ASCII)
 
 ```text
 +------------------+       +---------------------+       +------------------+
 |      UsuÃ¡rio     | --->  |     Streamlit UI    | --->  | LangChain Agent  |
 +------------------+       +---------------------+       +------------------+
                                    |   ^                          |
                                    v   |                          v
                             +-----------------+           +------------------+
                             |  Respostas/UX   |<----------|  Conversation    |
                             +-----------------+           |     Memory       |
                                                            +------------------+
                                    |
                                    v
                          +---------------------+
                          |       Tools         |
                          | (EDA / Visual / etc)|
                          +----------+----------+
                                     |
                                     v
                            +-------------------+
                            | Pandas DataFrame  |
                            +-------------------+
                                     |
                                     v
                       +-------------------------------+
                       |        LLM Providers          |
                       |       DeepSeek /  Groq /      |
                       |        Gemini / Ollama        |
                       +---------------+---------------+
                                       |
                                       v
                                +--------------+
                                | Fallback Mgr |
                                +------+-------+
                                       |
                                       v
                                +--------------+
                                | OfflineAgent |
                                +--------------+
 
### VisÃ£o de Alto NÃ­vel

```mermaid
graph TB
    subgraph "Frontend"
        UI[Streamlit UI]
        CHAT[Chat Interface]
        VIZ[VisualizaÃ§Ãµes]
    end
    
    subgraph "Core"
        AGENT[LangChain Agent]
        MEMORY[Memory System]
        TOOLS[Analysis Tools]
    end
    
    subgraph "Backend"
        LLM[LLM Provider]
        FALLBACK[Fallback System]
        OFFLINE[Offline Engine]
    end
    
    subgraph "Data"
        CSV[CSV Files]
        CACHE[Response Cache]
        HISTORY[Analysis History]
    end
    
    UI --> AGENT
    AGENT --> MEMORY
    AGENT --> TOOLS
    AGENT --> LLM
    LLM --> FALLBACK
    FALLBACK --> OFFLINE
    TOOLS --> CSV
    MEMORY --> HISTORY
    LLM --> CACHE
```

### Componentes Principais

#### 1. **Camada de ApresentaÃ§Ã£o (UI)**
- Framework: Streamlit
- Componentes: Chat, Upload, VisualizaÃ§Ãµes, HistÃ³rico
- Responsabilidade: Interface usuÃ¡rio, renderizaÃ§Ã£o

#### 2. **Camada de Processamento (Agent)**
- Framework: LangChain
- Componentes: Agent Executor, Tools, Memory
- Responsabilidade: OrquestraÃ§Ã£o, decisÃ£o, execuÃ§Ã£o

#### 3. **Camada de InteligÃªncia (LLM)**
- Providers: DeepSeek, Groq, Gemini, Ollama
- Sistema: Multi-provider com fallback
- Responsabilidade: NLP, geraÃ§Ã£o, entendimento

#### 4. **Camada de Dados**
- Storage: Session State (Streamlit)
- Formato: DataFrames (Pandas)
- PersistÃªncia: MemÃ³ria de sessÃ£o

### Fluxo de Dados

```
1. UsuÃ¡rio â†’ Pergunta em linguagem natural
2. UI â†’ Captura e envia para Agent
3. Agent â†’ Processa com LLM
4. LLM â†’ Identifica ferramenta apropriada
5. Tool â†’ Executa anÃ¡lise no DataFrame
6. Result â†’ Retorna para Agent
7. Agent â†’ Formata resposta
8. UI â†’ Exibe resultado ao usuÃ¡rio
```

---

## Tecnologias e Frameworks

### Core Technologies

| Tecnologia | VersÃ£o | PropÃ³sito |
|------------|--------|-----------|
| **Python** | 3.8+ | Linguagem base |
| **Streamlit** | 1.32.0+ | Interface web |
| **LangChain** | 0.1.0+ | Framework de IA |
| **Pandas** | 2.0.0+ | ManipulaÃ§Ã£o de dados |
| **Plotly** | 5.18.0+ | VisualizaÃ§Ãµes |
| **NumPy** | 1.24.0+ | ComputaÃ§Ã£o numÃ©rica |
| **SciPy** | 1.10.0+ | EstatÃ­sticas avanÃ§adas |

### LLM Providers (com Fallback Inteligente)

| Provider | Modelo | Tipo | Rate Limit | Contexto |
|----------|--------|------|------------|----------|
| **DeepSeek** | deepseek-chat-v3.1:free | Gratuito | 50/dia | 256k |
| **xAI Grok** | grok-4-fast:free | Gratuito | 100/dia | 2M |
| **Google Gemini** | gemini-2.5-flash-lite | Gratuito | 150/dia | 1M |
| **Meta Llama** | llama-3.2-3b:free | Gratuito | 200/dia | 128k |
| **Groq** | Llama-3.1-8b | Gratuito | 300/dia | 128k |

### Sistema de Fallback

O sistema tentarÃ¡ os provedores:
- **DeepSeek** (principal, Ã³timo para portuguÃªs)
- **xAI Grok 4** (2M de contexto, excelente para anÃ¡lises grandes)
- **Google Gemini 2.5** (1M de contexto, rÃ¡pido e eficiente)
- **Meta Llama 3.2** (bom desempenho geral)

### Bibliotecas Auxiliares

```python
langchain-openai      # IntegraÃ§Ã£o OpenAI
langchain-community   # Tools comunitÃ¡rias
openai               # Cliente OpenAI
python-dotenv        # VariÃ¡veis ambiente
typing-extensions    # Type hints
dataclasses         # Data structures
```

---

## Estrutura do Projeto

### OrganizaÃ§Ã£o de DiretÃ³rios

```
I2A2 - Desafio Extra/
â”‚
â”œâ”€â”€ ğŸ“ config/              # ConfiguraÃ§Ãµes centralizadas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py         # ConfiguraÃ§Ãµes principais
â”‚   â””â”€â”€ settings_alternatives.py  # ConfiguraÃ§Ãµes de fallback
â”‚
â”œâ”€â”€ ğŸ“ agents/              # Agentes de IA
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ eda_agent.py       # Agente principal
â”‚   â””â”€â”€ offline_agent.py   # Agente offline
â”‚
â”œâ”€â”€ ğŸ“ tools/               # Ferramentas de anÃ¡lise
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_analysis.py   # Ferramentas descritivas
â”‚   â”œâ”€â”€ visualizations.py  # Ferramentas visuais
â”‚   â””â”€â”€ insights.py        # Gerador de insights
â”‚
â”œâ”€â”€ ğŸ“ utils/               # UtilitÃ¡rios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ callbacks.py       # Callbacks Streamlit
â”‚   â”œâ”€â”€ memory.py          # Sistema de memÃ³ria
â”‚   â””â”€â”€ llm_fallback.py    # Gerenciador de fallback
â”‚
â”œâ”€â”€ ğŸ“ ui/                  # Interface do usuÃ¡rio
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ components.py       # Componentes UI
â”‚
â”œâ”€â”€ ğŸ“„ app_refatorado.py    # AplicaÃ§Ã£o principal (v2.0)
â”œâ”€â”€ ğŸ“„ app_backup.py        # Backup versÃ£o monolÃ­tica
â”œâ”€â”€ ğŸ“„ requirements.txt     # DependÃªncias
â”œâ”€â”€ ğŸ“„ README.md           # DocumentaÃ§Ã£o bÃ¡sica
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md     # Arquitetura detalhada
â”œâ”€â”€ ğŸ“„ MIGRATION_GUIDE.md  # Guia de migraÃ§Ã£o
â”œâ”€â”€ ğŸ“„ CHANGELOG.md        # HistÃ³rico de mudanÃ§as
â”œâ”€â”€ ğŸ“„ VERSION             # Controle de versÃ£o
â””â”€â”€ ğŸ“„ DOCUMENTATION.md    # Este arquivo
```

### MÃ³dulos e Responsabilidades

#### **app_refatorado.py** (80 linhas)
- Ponto de entrada da aplicaÃ§Ã£o
- ConfiguraÃ§Ã£o inicial
- OrquestraÃ§Ã£o de componentes

#### **config/settings.py**
- ConfiguraÃ§Ãµes do LLM
- ParÃ¢metros do sistema
- Constantes globais

#### **agents/eda_agent.py**
- CriaÃ§Ã£o do agente LangChain
- ConfiguraÃ§Ã£o de memÃ³ria
- IntegraÃ§Ã£o com ferramentas

#### **agents/offline_agent.py**
- Motor de regras offline
- DetecÃ§Ã£o de intenÃ§Ã£o
- Fallback inteligente

#### **tools/*.py**
- ImplementaÃ§Ã£o das ferramentas
- LÃ³gica de anÃ¡lise
- GeraÃ§Ã£o de visualizaÃ§Ãµes

#### **utils/*.py**
- FunÃ§Ãµes auxiliares
- Callbacks customizados
- Gerenciamento de estado

#### **ui/components.py**
- Componentes visuais
- RenderizaÃ§Ã£o de chat
- GestÃ£o de interface

---

## InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### Requisitos do Sistema

- Python 3.8 ou superior
- 4GB RAM mÃ­nimo (8GB recomendado)
- 500MB espaÃ§o em disco
- ConexÃ£o internet (para LLMs cloud)

### InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd "I2A2 - Desafio Extra"

# 2. Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Instale dependÃªncias
pip install -r requirements.txt

# 4. Execute a aplicaÃ§Ã£o
streamlit run app_refatorado.py
```

### ConfiguraÃ§Ã£o de API Keys

#### OpÃ§Ã£o 1: Arquivo .env
```bash
# .env
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENAI_API_KEY=sk-your-openai-key
GROQ_API_KEY=gsk_your-groq-key
GOOGLE_API_KEY=your-google-key
```

#### OpÃ§Ã£o 2: VariÃ¡veis de Ambiente
```bash
export OPENROUTER_API_KEY="sk-or-v1-your-key"
export OPENAI_API_KEY="sk-your-key"
```

#### OpÃ§Ã£o 3: Direto no cÃ³digo
```python
# config/settings.py
LLM_CONFIG = {
    "api_key": "your-key-here",
    ...
}
```
---

## Modos de Uso

### 1. Uso BÃ¡sico - Interface Web

1. **Iniciar aplicaÃ§Ã£o**
   ```bash
   streamlit run app_refatorado.py
   ```

2. **Carregar dados**
   - Clique em "Browse files"
   - Selecione arquivo CSV
   - Aguarde carregamento

3. **Fazer perguntas**
   - Digite no campo de chat
   - Pressione Enter
   - Visualize resultados

### 2. Uso AvanÃ§ado - Comandos EspecÃ­ficos

#### AnÃ¡lise Completa
```
"FaÃ§a uma anÃ¡lise completa incluindo estatÃ­sticas, distribuiÃ§Ãµes, outliers e correlaÃ§Ãµes"
```

#### AnÃ¡lise Direcionada
```
"Analise a variÃ¡vel Amount mostrando distribuiÃ§Ã£o, outliers e correlaÃ§Ãµes"
```

#### ComparaÃ§Ãµes
```
"Compare V1 com V2 usando scatter plot"
"Mostre a relaÃ§Ã£o entre Time e Amount"
```

#### Insights
```
"Gere conclusÃµes sobre os dados analisados"
"Quais padrÃµes vocÃª identificou?"
```

### 3. Uso ProgramÃ¡tico

```python
# Importar componentes
from agents.eda_agent import create_eda_agent
from tools import ALL_TOOLS
import pandas as pd

# Carregar dados
df = pd.read_csv("data.csv")

# Criar agente
agent = create_eda_agent()

# Executar anÃ¡lise
result = agent.invoke({
    "input": "AnÃ¡lise completa dos dados"
})

print(result['output'])
```

### 4. Modo Offline

Quando o LLM nÃ£o estÃ¡ disponÃ­vel:

```python
from agents.offline_agent import offline_agent

# Usar comandos diretos
result = offline_agent.invoke({
    "input": "estatÃ­sticas descritivas"
})
```

---

## Guia de Desenvolvimento

### Adicionando Nova Ferramenta

#### 1. Criar arquivo em tools/
```python
# tools/my_tool.py
from langchain.tools import tool
import streamlit as st

@tool
def my_custom_analysis(parameter: str) -> str:
    """DescriÃ§Ã£o da ferramenta."""
    df = st.session_state.df
    # ImplementaÃ§Ã£o
    return "Resultado"
```

#### 2. Registrar em tools/__init__.py
```python
from .my_tool import my_custom_analysis

ALL_TOOLS = [
    ...,
    my_custom_analysis
]
```

#### 3. Atualizar agente offline (opcional)
```python
# agents/offline_agent.py
self.keyword_tool_mapping = {
    ...,
    'minha_palavra': 'my_custom_analysis'
}
```

### Modificando ConfiguraÃ§Ãµes

```python
# config/settings.py
class Settings:
    # LLM Config
    LLM_CONFIG = {
        "model_name": "novo-modelo",
        "temperature": 0.2,
        "max_tokens": 3000
    }
    
    # System Config
    MAX_FILE_SIZE = 200_000_000  # 200MB
    SUPPORTED_FORMATS = ['.csv', '.xlsx']
    
    # UI Config
    CHAT_HEIGHT = 500
    SIDEBAR_WIDTH = 300
```

### Testando Componentes

```python
# tests/test_tools.py
import pytest
from tools.data_analysis import get_data_description

def test_data_description():
    result = get_data_description()
    assert "InformaÃ§Ãµes Gerais" in result
    assert "DimensÃµes" in result
```

---

## Exemplos PrÃ¡ticos

### Exemplo 1: AnÃ¡lise de Fraude em CartÃµes

```python
# Dataset: creditcard.csv
Perguntas sugeridas:

1. "VisÃ£o geral dos dados de fraude"
2. "EstatÃ­sticas da coluna Amount"
3. "Existe correlaÃ§Ã£o entre as variÃ¡veis V?"
4. "Identifique outliers em Amount"
5. "Compare transaÃ§Ãµes normais vs fraude"
6. "Gere conclusÃµes sobre padrÃµes de fraude"
```

### Exemplo 2: AnÃ¡lise de Vendas

```python
# Dataset: sales.csv
Workflow:

1. "DescriÃ§Ã£o geral do dataset de vendas"
2. "Qual a distribuiÃ§Ã£o de vendas por mÃªs?"
3. "Existem outliers nos valores de venda?"
4. "CorrelaÃ§Ã£o entre preÃ§o e quantidade"
5. "TendÃªncias temporais nas vendas"
6. "Principais insights sobre o negÃ³cio"
```

### Exemplo 3: AnÃ¡lise ExploratÃ³ria Completa

```python
# Comando Ãºnico para anÃ¡lise completa:
"Execute uma anÃ¡lise exploratÃ³ria completa incluindo:
1. DescriÃ§Ã£o dos dados
2. EstatÃ­sticas de todas as variÃ¡veis
3. IdentificaÃ§Ã£o de outliers
4. Matrix de correlaÃ§Ã£o
5. Principais distribuiÃ§Ãµes
6. GeraÃ§Ã£o de insights e recomendaÃ§Ãµes"
```

---

## Troubleshooting

### Problemas Comuns e SoluÃ§Ãµes

#### 1. Rate Limit Excedido
**Erro:** `Rate limit exceeded: free-models-per-day`

**SoluÃ§Ãµes:**
- Adicione crÃ©ditos no OpenRouter ($10 = 1000 req/dia)
- Use provider alternativo (Groq, Gemini)
- Use modo offline temporariamente

#### 2. Erro de MemÃ³ria
**Erro:** `'query' KeyError`

**SoluÃ§Ã£o:**
```python
# Limpar sessÃ£o
streamlit run app_refatorado.py --server.runOnSave true
```

#### 3. Arquivo CSV NÃ£o Carrega
**Erro:** `Error loading file`

**Verificar:**
- Encoding (usar UTF-8)
- Separador (vÃ­rgula padrÃ£o)
- Tamanho < 200MB
- Formato vÃ¡lido

#### 4. GrÃ¡ficos NÃ£o Aparecem
**Erro:** VisualizaÃ§Ã£o em branco

**SoluÃ§Ãµes:**
- Atualizar Plotly: `pip install --upgrade plotly`
- Limpar cache: `streamlit cache clear`
- Verificar dados numÃ©ricos

#### 5. LLM NÃ£o Responde
**Erro:** Timeout ou sem resposta

**Verificar:**
- API Key vÃ¡lida
- ConexÃ£o internet
- Provider disponÃ­vel
- Usar fallback system

### Logs e Debug

#### Ativar logs detalhados
```python
# config/settings.py
LOGGING_LEVEL = "DEBUG"
```

#### Verificar logs
```bash
# Terminal onde roda streamlit
tail -f ~/.streamlit/logs/*.log
```

#### Debug mode
```python
# app_refatorado.py
import streamlit as st
st.set_page_config(page_title="EDA Agent", layout="wide")
st.write(st.session_state)  # Debug session
```

---

## ReferÃªncias e Recursos

### DocumentaÃ§Ã£o Oficial

- [LangChain Docs](https://python.langchain.com/docs/get_started/introduction)
- [Streamlit Docs](https://docs.streamlit.io/)
- [Plotly Python](https://plotly.com/python/)
- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)

### Tutoriais e Guias

- [Building AI Agents with LangChain](https://www.langchain.com/agents)
- [Streamlit Best Practices](https://blog.streamlit.io/best-practices/)
- [EDA with Python](https://www.kaggle.com/learn/data-visualization)

---

## ApÃªndices

### A. GlossÃ¡rio de Termos

| Termo | DefiniÃ§Ã£o |
|-------|-----------|
| **EDA** | Exploratory Data Analysis - AnÃ¡lise ExploratÃ³ria de Dados |
| **LLM** | Large Language Model - Modelo de Linguagem Grande |
| **Agent** | Sistema autÃ´nomo que toma decisÃµes |
| **Tool** | Ferramenta executÃ¡vel pelo agente |
| **Memory** | Sistema de memÃ³ria conversacional |
| **Fallback** | Sistema de contingÃªncia |
| **Provider** | Fornecedor de serviÃ§o LLM |
| **Outlier** | Valor atÃ­pico nos dados |
| **Correlation** | RelaÃ§Ã£o estatÃ­stica entre variÃ¡veis |

### B. Comandos RÃ¡pidos

```bash
# Desenvolvimento
streamlit run app_refatorado.py --server.runOnSave true

# ProduÃ§Ã£o
streamlit run app_refatorado.py --server.headless true

# Debug
streamlit run app_refatorado.py --logger.level debug

# Performance
streamlit run app_refatorado.py --server.enableCORS false
```

### C. VariÃ¡veis de Ambiente

```bash
# LLM Configuration
OPENROUTER_API_KEY=
OPENAI_API_KEY=
GROQ_API_KEY=
GOOGLE_API_KEY=

# System Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
STREAMLIT_THEME=dark

# Debug
LANGCHAIN_VERBOSE=true
STREAMLIT_LOGGER_LEVEL=info
```

---

## LicenÃ§a e CrÃ©ditos

### LicenÃ§a
MIT License - Uso livre com atribuiÃ§Ã£o

### Autores
- Desenvolvimento: Time de Engenharia
- Arquitetura: Solution Architects
- UI/UX: Design Team

### Agradecimentos
- LangChain Community
- Streamlit Team
- OpenRouter/DeepSeek
- Comunidade Open Source

---

**VersÃ£o:** 2.0.1  
**Ãšltima AtualizaÃ§Ã£o:** 2025-09-28  
**Status:** ProduÃ§Ã£o  
**Contato:** [suporte@exemplo.com]

---

*Esta documentaÃ§Ã£o Ã© um documento vivo e serÃ¡ atualizada continuamente com melhorias e novos recursos.*
