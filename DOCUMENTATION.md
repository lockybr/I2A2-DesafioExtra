# üìö Documenta√ß√£o Completa - I2A2 EDA Agent v2.0.3

## √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Caracter√≠sticas Principais](#caracter√≠sticas-principais)
3. [Funcionalidades Detalhadas](#funcionalidades-detalhadas)
4. [Arquitetura da Solu√ß√£o](#arquitetura-da-solu√ß√£o)
5. [Tecnologias e Frameworks](#tecnologias-e-frameworks)
6. [Estrutura do Projeto](#estrutura-do-projeto)
7. [Instala√ß√£o e Configura√ß√£o](#instala√ß√£o-e-configura√ß√£o)
8. [Modos de Uso](#modos-de-uso)
9. [Guia de Desenvolvimento](#guia-de-desenvolvimento)
10. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)
11. [Troubleshooting](#troubleshooting)
12. [Refer√™ncias e Recursos](#refer√™ncias-e-recursos)

---

## Vis√£o Geral

### O que √© o I2A2 EDA Agent?

O **I2A2 EDA Agent** √© uma aplica√ß√£o inteligente de an√°lise explorat√≥ria de dados (Exploratory Data Analysis) que combina o poder de m√∫ltiplas LLMs com ferramentas estat√≠sticas robustas. Desenvolvido com uma arquitetura modular e escal√°vel, permite que analistas e cientistas de dados realizem an√°lises complexas usando linguagem natural.

**Powered by Saulo Belchior** - Vers√£o 2.0.3

### Prop√≥sito

- **Democratizar** a an√°lise de dados atrav√©s de interface conversacional
- **Automatizar** tarefas repetitivas de EDA
- **Acelerar** o processo de descoberta de insights
- **Manter contexto** entre an√°lises para constru√ß√£o incremental de conhecimento

### Diferenciais

1. **Sistema Multi-LLM**: 3 modelos gratuitos com fallback autom√°tico
2. **Sele√ß√£o de Modelo**: Usu√°rio escolhe qual LLM usar
3. **Transpar√™ncia Total**: Cada resposta mostra qual modelo foi usado
4. **Agente Inteligente com Mem√≥ria**: Mant√©m contexto entre an√°lises
5. **Modo Offline**: Funciona mesmo sem acesso a LLMs
6. **Arquitetura Modular**: F√°cil manuten√ß√£o e extens√£o
7. **Interface Intuitiva**: An√°lises complexas com comandos simples

---

## Caracter√≠sticas Principais

### üß† Intelig√™ncia Artificial

- **LangChain Framework**: Orquestra√ß√£o de agentes e ferramentas
- **Mem√≥ria Conversacional**: ConversationBufferWindowMemory mant√©m contexto
- **Processamento de Linguagem Natural**: Entende comandos em portugu√™s e ingl√™s
- **Gera√ß√£o Autom√°tica de Insights**: Sintetiza descobertas em conclus√µes acion√°veis

### üõ°Ô∏è Robustez e Confiabilidade

- **Sistema Multi-LLM**: 3 modelos gratuitos (xAI Grok, Meta Llama 3.2, DeepSeek)
- **Fallback Autom√°tico**: Troca de modelo em caso de falha
- **Sele√ß√£o Manual**: Usu√°rio pode for√ßar modelo espec√≠fico
- **Transpar√™ncia**: Cada resposta mostra qual modelo foi usado
- **Modo Offline**: An√°lises baseadas em regras quando LLM indispon√≠vel
- **Tratamento de Erros**: Feedback claro e op√ß√µes de recupera√ß√£o

### üìä Capacidades Anal√≠ticas

- **7 Ferramentas Especializadas**: Cobertura completa de t√©cnicas EDA
- **Gera√ß√£o de Insights**: Ferramenta para sintetizar conclus√µes
- **Visualiza√ß√µes Interativas**: Gr√°ficos Plotly com zoom e exporta√ß√£o
- **An√°lise Estat√≠stica Completa**: Medidas descritivas, correla√ß√µes, outliers
- **Detec√ß√£o de Padr√µes**: Identifica√ß√£o autom√°tica de anomalias e tend√™ncias

### üé® Interface e Experi√™ncia

- **Interface Web Moderna**: Streamlit com design responsivo
- **Chat Conversacional**: Intera√ß√£o natural como conversa
- **Sugest√µes Inteligentes**: Perguntas organizadas por categoria
- **Hist√≥rico de An√°lises**: Rastreamento de todas as intera√ß√µes

---

## Funcionalidades Detalhadas

### 1. Ferramentas de An√°lise

#### üìã **get_data_description**
```python
Prop√≥sito: Vis√£o geral do dataset
Retorna: 
- Dimens√µes (linhas √ó colunas)
- Tipos de dados
- Valores ausentes
- Estat√≠sticas b√°sicas
```

#### üìà **get_descriptive_statistics**
```python
Prop√≥sito: Estat√≠sticas descritivas detalhadas
Par√¢metros: column (opcional)
Retorna:
- Count, mean, std, min, max
- Quartis (25%, 50%, 75%)
- Skewness e Kurtosis
```

#### üìä **plot_histogram**
```python
Prop√≥sito: Visualizar distribui√ß√£o de vari√°vel
Par√¢metros: column (obrigat√≥rio)
Retorna: Histograma interativo Plotly
```

#### üì¶ **plot_boxplot**
```python
Prop√≥sito: Identificar outliers de uma coluna
Par√¢metros: column (obrigat√≥rio)
Retorna: Boxplot com outliers destacados
```

#### üì¶ **plot_multiple_boxplots**
```python
Prop√≥sito: An√°lise de outliers de todas as colunas
Par√¢metros: Nenhum
Retorna: Grid de boxplots
```

#### üîó **plot_correlation_heatmap**
```python
Prop√≥sito: Matriz de correla√ß√£o entre vari√°veis
Par√¢metros: Nenhum
Retorna: Heatmap colorido com valores
```

#### üéØ **plot_scatter**
```python
Prop√≥sito: Rela√ß√£o entre duas vari√°veis
Par√¢metros: x_column, y_column
Retorna: Gr√°fico de dispers√£o com linha de tend√™ncia
```

#### üí° **generate_insights_and_conclusions**
```python
Prop√≥sito: Sintetizar an√°lises em insights
Par√¢metros: Nenhum
Retorna: Conclus√µes baseadas no hist√≥rico
```

### 2. Modos de Opera√ß√£o

#### Modo Normal (Com LLM)
- Processamento completo com IA
- Entendimento de contexto complexo
- Gera√ß√£o de insights sofisticados
- Mem√≥ria de longo prazo

#### Modo Offline (Sem LLM)
- Detec√ß√£o baseada em regras
- An√°lise por palavras-chave
- Execu√ß√£o direta de ferramentas
- Fallback inteligente
#### Modo H√≠brido
- Tenta LLM principal
- √öltimo recurso: modo offline
- Transpar√™ncia sobre modo usado

##  Framework escolhida: LangChain
  
  O projeto adota o LangChain como framework central para aplica√ß√µes com LLMs. Ele simplifica a orquestra√ß√£o do agente, reduz boilerplate e garante consist√™ncia do hist√≥rico.
  
  - **Tools nativas (`@tool`)**: o decorador transforma fun√ß√µes Python em ferramentas com JSON Schema para tool-calling, usadas no m√≥dulo `tools/`.
  - **AgentExecutor (motor do agente)**: recebe o LLM, as ferramentas e a pergunta do usu√°rio, e cuida de:
    - Formatar o prompt com as ferramentas dispon√≠veis
    - Invocar o LLM e interpretar qual ferramenta e argumentos usar
    - Executar a fun√ß√£o Python correspondente
    - (Opcional) Enviar o resultado de volta ao LLM para resposta final em linguagem natural
    - Gerenciar a mem√≥ria e o hist√≥rico da sess√£o
  - **Mem√≥ria Conversacional**: integra√ß√£o com `ConversationSummaryBufferMemory`/`ConversationBufferWindowMemory` preservando contexto entre intera√ß√µes.
  - **Integra√ß√µes**: compat√≠vel com m√∫ltiplos provedores e modelos (via OpenRouter, OpenAI, Groq, Gemini, Ollama), reduzindo a configura√ß√£o.
  
  Benef√≠cio no projeto: focamos na l√≥gica das ferramentas e UX, enquanto o LangChain gerencia o ciclo agente‚ÜîLLM‚Üîferramentas.

## Arquitetura da Solu√ß√£o

### Diagrama de Vis√£o Geral
   U[Usu√°rio] --> UI[Streamlit UI]
   UI --> A[LangChain Agent Executor]
   A -- mem√≥ria --> M[Conversation Memory]
   T --> D[DataFrame (Pandas)]
   A -- LLM --> L[LLM Providers\n(DeepSeek/Groq/Gemini/Ollama)]
   L --> F[Fallback Manager]
   F --> O[Offline Agent]
   A --> R[Respostas/Visualiza√ß√µes]
  ```
  R --> UI
  ```
 
 #### Diagrama (ASCII)
 
 ```text
 +------------------+       +---------------------+       +------------------+
 |      Usu√°rio     | --->  |     Streamlit UI    | --->  | LangChain Agent  |
 +------------------+       +---------------------+       +------------------+
                                    |   ^                          |
                                    v   |                          v
                             +-----------------+           +------------------+
                             |  Respostas/UX   |<----------|  Conversation    |
                             +-----------------+           |     Memory       |
                                                            +------------------+
                                    |
                                    v
                          +---------------------+
                          |       Tools         |
                          | (EDA / Visual / etc)|
                          +----------+----------+
                                     |
                                     v
                            +-------------------+
                            | Pandas DataFrame  |
                            +-------------------+
                                     |
                                     v
                       +-------------------------------+
                       |        LLM Providers          |
                       |       DeepSeek /  Groq /      |
                       |        Gemini / Ollama        |
                       +---------------+---------------+
                                       |
                                       v
                                +--------------+
                                | Fallback Mgr |
                                +------+-------+
                                       |
                                       v
                                +--------------+
                                | OfflineAgent |
                                +--------------+
 
### Vis√£o de Alto N√≠vel

```mermaid
graph TB
    subgraph "Frontend"
        UI[Streamlit UI]
        CHAT[Chat Interface]
        VIZ[Visualiza√ß√µes]
    end
    
    subgraph "Core"
        AGENT[LangChain Agent]
        MEMORY[Memory System]
        TOOLS[Analysis Tools]
    end
    
    subgraph "Backend"
        LLM[LLM Provider]
        FALLBACK[Fallback System]
        OFFLINE[Offline Engine]
    end
    
    subgraph "Data"
        CSV[CSV Files]
        CACHE[Response Cache]
        HISTORY[Analysis History]
    end
    
    UI --> AGENT
    AGENT --> MEMORY
    AGENT --> TOOLS
    AGENT --> LLM
    LLM --> FALLBACK
    FALLBACK --> OFFLINE
    TOOLS --> CSV
    MEMORY --> HISTORY
    LLM --> CACHE
```

### Componentes Principais

#### 1. **Camada de Apresenta√ß√£o (UI)**
- Framework: Streamlit
- Componentes: Chat, Upload, Visualiza√ß√µes, Hist√≥rico
- Responsabilidade: Interface usu√°rio, renderiza√ß√£o

#### 2. **Camada de Processamento (Agent)**
- Framework: LangChain
- Componentes: Agent Executor, Tools, Memory
- Responsabilidade: Orquestra√ß√£o, decis√£o, execu√ß√£o

#### 3. **Camada de Intelig√™ncia (LLM)**
- Providers: DeepSeek, Groq, Gemini, Ollama
- Sistema: Multi-provider com fallback
- Responsabilidade: NLP, gera√ß√£o, entendimento

#### 4. **Camada de Dados**
- Storage: Session State (Streamlit)
- Formato: DataFrames (Pandas)
- Persist√™ncia: Mem√≥ria de sess√£o

### Fluxo de Dados

```
1. Usu√°rio ‚Üí Pergunta em linguagem natural
2. UI ‚Üí Captura e envia para Agent
3. Agent ‚Üí Processa com LLM
4. LLM ‚Üí Identifica ferramenta apropriada
5. Tool ‚Üí Executa an√°lise no DataFrame
6. Result ‚Üí Retorna para Agent
7. Agent ‚Üí Formata resposta
8. UI ‚Üí Exibe resultado ao usu√°rio
```

---

## Tecnologias e Frameworks

### Core Technologies

| Tecnologia | Vers√£o | Prop√≥sito |
|------------|--------|-----------|
| **Python** | 3.8+ | Linguagem base |
| **Streamlit** | 1.32.0+ | Interface web |
| **LangChain** | 0.1.0+ | Framework de IA |
| **Pandas** | 2.0.0+ | Manipula√ß√£o de dados |
| **Plotly** | 5.18.0+ | Visualiza√ß√µes |
| **NumPy** | 1.24.0+ | Computa√ß√£o num√©rica |
| **SciPy** | 1.10.0+ | Estat√≠sticas avan√ßadas |

### LLM Providers (com Fallback Inteligente)

| Provider | Modelo | Tipo | Rate Limit | Contexto |
|----------|--------|------|------------|----------|
| **DeepSeek** | deepseek-chat-v3.1:free | Gratuito | 50/dia | 256k |
| **xAI Grok** | grok-4-fast:free | Gratuito | 100/dia | 2M |
| **Google Gemini** | gemini-2.5-flash-lite | Gratuito | 150/dia | 1M |
| **Meta Llama** | llama-3.2-3b:free | Gratuito | 200/dia | 128k |
| **Groq** | Llama-3.1-8b | Gratuito | 300/dia | 128k |

### Sistema de Fallback

O sistema tentar√° os provedores:
- **DeepSeek** (principal, √≥timo para portugu√™s)
- **xAI Grok 4** (2M de contexto, excelente para an√°lises grandes)
- **Google Gemini 2.5** (1M de contexto, r√°pido e eficiente)
- **Meta Llama 3.2** (bom desempenho geral)

### Bibliotecas Auxiliares

```python
langchain-openai      # Integra√ß√£o OpenAI
langchain-community   # Tools comunit√°rias
openai               # Cliente OpenAI
python-dotenv        # Vari√°veis ambiente
typing-extensions    # Type hints
dataclasses         # Data structures
```

---

## Estrutura do Projeto

### Organiza√ß√£o de Diret√≥rios

```
I2A2 - Desafio Extra/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ config/              # Configura√ß√µes centralizadas
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings.py         # Configura√ß√µes principais
‚îÇ   ‚îî‚îÄ‚îÄ settings_alternatives.py  # Configura√ß√µes de fallback
‚îÇ
‚îú‚îÄ‚îÄ üìÅ agents/              # Agentes de IA
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ eda_agent.py       # Agente principal
‚îÇ   ‚îî‚îÄ‚îÄ offline_agent.py   # Agente offline
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tools/               # Ferramentas de an√°lise
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_analysis.py   # Ferramentas descritivas
‚îÇ   ‚îú‚îÄ‚îÄ visualizations.py  # Ferramentas visuais
‚îÇ   ‚îî‚îÄ‚îÄ insights.py        # Gerador de insights
‚îÇ
‚îú‚îÄ‚îÄ üìÅ utils/               # Utilit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ callbacks.py       # Callbacks Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ memory.py          # Sistema de mem√≥ria
‚îÇ   ‚îî‚îÄ‚îÄ llm_fallback.py    # Gerenciador de fallback
‚îÇ
‚îú‚îÄ‚îÄ üìÅ ui/                  # Interface do usu√°rio
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ components.py       # Componentes UI
‚îÇ
‚îú‚îÄ‚îÄ üìÑ app_refatorado.py    # Aplica√ß√£o principal (v2.0)
‚îú‚îÄ‚îÄ üìÑ app_backup.py        # Backup vers√£o monol√≠tica
‚îú‚îÄ‚îÄ üìÑ requirements.txt     # Depend√™ncias
‚îú‚îÄ‚îÄ üìÑ README.md           # Documenta√ß√£o b√°sica
‚îú‚îÄ‚îÄ üìÑ ARCHITECTURE.md     # Arquitetura detalhada
‚îú‚îÄ‚îÄ üìÑ MIGRATION_GUIDE.md  # Guia de migra√ß√£o
‚îú‚îÄ‚îÄ üìÑ CHANGELOG.md        # Hist√≥rico de mudan√ßas
‚îú‚îÄ‚îÄ üìÑ VERSION             # Controle de vers√£o
‚îî‚îÄ‚îÄ üìÑ DOCUMENTATION.md    # Este arquivo
```

### M√≥dulos e Responsabilidades

#### **app_refatorado.py** (80 linhas)
- Ponto de entrada da aplica√ß√£o
- Configura√ß√£o inicial
- Orquestra√ß√£o de componentes

#### **config/settings.py**
- Configura√ß√µes do LLM
- Par√¢metros do sistema
- Constantes globais

#### **agents/eda_agent.py**
- Cria√ß√£o do agente LangChain
- Configura√ß√£o de mem√≥ria
- Integra√ß√£o com ferramentas

#### **agents/offline_agent.py**
- Motor de regras offline
- Detec√ß√£o de inten√ß√£o
- Fallback inteligente

#### **tools/*.py**
- Implementa√ß√£o das ferramentas
- L√≥gica de an√°lise
- Gera√ß√£o de visualiza√ß√µes

#### **utils/*.py**
- Fun√ß√µes auxiliares
- Callbacks customizados
- Gerenciamento de estado

#### **ui/components.py**
- Componentes visuais
- Renderiza√ß√£o de chat
- Gest√£o de interface

---

## Instala√ß√£o e Configura√ß√£o

### Requisitos do Sistema

- Python 3.8 ou superior
- 4GB RAM m√≠nimo (8GB recomendado)
- 500MB espa√ßo em disco
- Conex√£o internet (para LLMs cloud)

### Instala√ß√£o R√°pida

```bash
# 1. Clone o reposit√≥rio
git clone <repository-url>
cd "I2A2 - Desafio Extra"

# 2. Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 3. Instale depend√™ncias
pip install -r requirements.txt

# 4. Execute a aplica√ß√£o
streamlit run app_refatorado.py
```

### Configura√ß√£o de API Keys

#### Op√ß√£o 1: Arquivo .env
```bash
# .env
OPENROUTER_API_KEY=sk-or-v1-your-key-here
OPENAI_API_KEY=sk-your-openai-key
GROQ_API_KEY=gsk_your-groq-key
GOOGLE_API_KEY=your-google-key
```

#### Op√ß√£o 2: Vari√°veis de Ambiente
```bash
export OPENROUTER_API_KEY="sk-or-v1-your-key"
export OPENAI_API_KEY="sk-your-key"
```

#### Op√ß√£o 3: Direto no c√≥digo
```python
# config/settings.py
LLM_CONFIG = {
    "api_key": "your-key-here",
    ...
}
```
---

## Modos de Uso

### 1. Uso B√°sico - Interface Web

1. **Iniciar aplica√ß√£o**
   ```bash
   streamlit run app_refatorado.py
   ```

2. **Carregar dados**
   - Clique em "Browse files"
   - Selecione arquivo CSV
   - Aguarde carregamento

3. **Fazer perguntas**
   - Digite no campo de chat
   - Pressione Enter
   - Visualize resultados

### 2. Uso Avan√ßado - Comandos Espec√≠ficos

#### An√°lise Completa
```
"Fa√ßa uma an√°lise completa incluindo estat√≠sticas, distribui√ß√µes, outliers e correla√ß√µes"
```

#### An√°lise Direcionada
```
"Analise a vari√°vel Amount mostrando distribui√ß√£o, outliers e correla√ß√µes"
```

#### Compara√ß√µes
```
"Compare V1 com V2 usando scatter plot"
"Mostre a rela√ß√£o entre Time e Amount"
```

#### Insights
```
"Gere conclus√µes sobre os dados analisados"
"Quais padr√µes voc√™ identificou?"
```

### 3. Uso Program√°tico

```python
# Importar componentes
from agents.eda_agent import create_eda_agent
from tools import ALL_TOOLS
import pandas as pd

# Carregar dados
df = pd.read_csv("data.csv")

# Criar agente
agent = create_eda_agent()

# Executar an√°lise
result = agent.invoke({
    "input": "An√°lise completa dos dados"
})

print(result['output'])
```

### 4. Modo Offline

Quando o LLM n√£o est√° dispon√≠vel:

```python
from agents.offline_agent import offline_agent

# Usar comandos diretos
result = offline_agent.invoke({
    "input": "estat√≠sticas descritivas"
})
```

---

## Guia de Desenvolvimento

### Adicionando Nova Ferramenta

#### 1. Criar arquivo em tools/
```python
# tools/my_tool.py
from langchain.tools import tool
import streamlit as st

@tool
def my_custom_analysis(parameter: str) -> str:
    """Descri√ß√£o da ferramenta."""
    df = st.session_state.df
    # Implementa√ß√£o
    return "Resultado"
```

#### 2. Registrar em tools/__init__.py
```python
from .my_tool import my_custom_analysis

ALL_TOOLS = [
    ...,
    my_custom_analysis
]
```

#### 3. Atualizar agente offline (opcional)
```python
# agents/offline_agent.py
self.keyword_tool_mapping = {
    ...,
    'minha_palavra': 'my_custom_analysis'
}
```

### Modificando Configura√ß√µes

```python
# config/settings.py
class Settings:
    # LLM Config
    LLM_CONFIG = {
        "model_name": "novo-modelo",
        "temperature": 0.2,
        "max_tokens": 3000
    }
    
    # System Config
    MAX_FILE_SIZE = 200_000_000  # 200MB
    SUPPORTED_FORMATS = ['.csv', '.xlsx']
    
    # UI Config
    CHAT_HEIGHT = 500
    SIDEBAR_WIDTH = 300
```

### Testando Componentes

```python
# tests/test_tools.py
import pytest
from tools.data_analysis import get_data_description

def test_data_description():
    result = get_data_description()
    assert "Informa√ß√µes Gerais" in result
    assert "Dimens√µes" in result
```

---

## Exemplos Pr√°ticos

### Exemplo 1: An√°lise de Fraude em Cart√µes

```python
# Dataset: creditcard.csv
Perguntas sugeridas:

1. "Vis√£o geral dos dados de fraude"
2. "Estat√≠sticas da coluna Amount"
3. "Existe correla√ß√£o entre as vari√°veis V?"
4. "Identifique outliers em Amount"
5. "Compare transa√ß√µes normais vs fraude"
6. "Gere conclus√µes sobre padr√µes de fraude"
```

### Exemplo 2: An√°lise de Vendas

```python
# Dataset: sales.csv
Workflow:

1. "Descri√ß√£o geral do dataset de vendas"
2. "Qual a distribui√ß√£o de vendas por m√™s?"
3. "Existem outliers nos valores de venda?"
4. "Correla√ß√£o entre pre√ßo e quantidade"
5. "Tend√™ncias temporais nas vendas"
6. "Principais insights sobre o neg√≥cio"
```

### Exemplo 3: An√°lise Explorat√≥ria Completa

```python
# Comando √∫nico para an√°lise completa:
"Execute uma an√°lise explorat√≥ria completa incluindo:
1. Descri√ß√£o dos dados
2. Estat√≠sticas de todas as vari√°veis
3. Identifica√ß√£o de outliers
4. Matrix de correla√ß√£o
5. Principais distribui√ß√µes
6. Gera√ß√£o de insights e recomenda√ß√µes"
```

---

## Troubleshooting

### Problemas Comuns e Solu√ß√µes

#### 1. Rate Limit Excedido
**Erro:** `Rate limit exceeded: free-models-per-day`

**Solu√ß√µes:**
- Adicione cr√©ditos no OpenRouter ($10 = 1000 req/dia)
- Use provider alternativo (Groq, Gemini)
- Use modo offline temporariamente

#### 2. Erro de Mem√≥ria
**Erro:** `'query' KeyError`

**Solu√ß√£o:**
```python
# Limpar sess√£o
streamlit run app_refatorado.py --server.runOnSave true
```

#### 3. Arquivo CSV N√£o Carrega
**Erro:** `Error loading file`

**Verificar:**
- Encoding (usar UTF-8)
- Separador (v√≠rgula padr√£o)
- Tamanho < 200MB
- Formato v√°lido

#### 4. Gr√°ficos N√£o Aparecem
**Erro:** Visualiza√ß√£o em branco

**Solu√ß√µes:**
- Atualizar Plotly: `pip install --upgrade plotly`
- Limpar cache: `streamlit cache clear`
- Verificar dados num√©ricos

#### 5. LLM N√£o Responde
**Erro:** Timeout ou sem resposta

**Verificar:**
- API Key v√°lida
- Conex√£o internet
- Provider dispon√≠vel
- Usar fallback system

### Logs e Debug

#### Ativar logs detalhados
```python
# config/settings.py
LOGGING_LEVEL = "DEBUG"
```

#### Verificar logs
```bash
# Terminal onde roda streamlit
tail -f ~/.streamlit/logs/*.log
```

#### Debug mode
```python
# app_refatorado.py
import streamlit as st
st.set_page_config(page_title="EDA Agent", layout="wide")
st.write(st.session_state)  # Debug session
```

---

## Refer√™ncias e Recursos

### Documenta√ß√£o Oficial

- [LangChain Docs](https://python.langchain.com/docs/get_started/introduction)
- [Streamlit Docs](https://docs.streamlit.io/)
- [Plotly Python](https://plotly.com/python/)
- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/index.html)

### Tutoriais e Guias

- [Building AI Agents with LangChain](https://www.langchain.com/agents)
- [Streamlit Best Practices](https://blog.streamlit.io/best-practices/)
- [EDA with Python](https://www.kaggle.com/learn/data-visualization)

---

## Ap√™ndices

### A. Gloss√°rio de Termos

| Termo | Defini√ß√£o |
|-------|-----------|
| **EDA** | Exploratory Data Analysis - An√°lise Explorat√≥ria de Dados |
| **LLM** | Large Language Model - Modelo de Linguagem Grande |
| **Agent** | Sistema aut√¥nomo que toma decis√µes |
| **Tool** | Ferramenta execut√°vel pelo agente |
| **Memory** | Sistema de mem√≥ria conversacional |
| **Fallback** | Sistema de conting√™ncia |
| **Provider** | Fornecedor de servi√ßo LLM |
| **Outlier** | Valor at√≠pico nos dados |
| **Correlation** | Rela√ß√£o estat√≠stica entre vari√°veis |

### B. Comandos R√°pidos

```bash
# Desenvolvimento
streamlit run app_refatorado.py --server.runOnSave true

# Produ√ß√£o
streamlit run app_refatorado.py --server.headless true

# Debug
streamlit run app_refatorado.py --logger.level debug

# Performance
streamlit run app_refatorado.py --server.enableCORS false
```

### C. Vari√°veis de Ambiente

```bash
# LLM Configuration
OPENROUTER_API_KEY=
OPENAI_API_KEY=
GROQ_API_KEY=
GOOGLE_API_KEY=

# System Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
STREAMLIT_THEME=dark

# Debug
LANGCHAIN_VERBOSE=true
STREAMLIT_LOGGER_LEVEL=info
```

---

## Licen√ßa e Cr√©ditos

### Licen√ßa
MIT License - Uso livre com atribui√ß√£o

### Autores
- Desenvolvimento: Time de Engenharia
- Arquitetura: Solution Architects
- UI/UX: Design Team

### Agradecimentos
- LangChain Community
- Streamlit Team
- OpenRouter/DeepSeek
- Comunidade Open Source

---

**Vers√£o:** 2.0.1  
**√öltima Atualiza√ß√£o:** 2025-09-28  
**Status:** Produ√ß√£o  
**Contato:** [suporte@exemplo.com]

---

*Esta documenta√ß√£o √© um documento vivo e ser√° atualizada continuamente com melhorias e novos recursos.*
