# ğŸš€ InstruÃ§Ãµes de Deploy - I2A2 EDA Agent

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- 2GB de espaÃ§o em disco livre
- ConexÃ£o com internet (para instalaÃ§Ã£o de dependÃªncias)

## ğŸ”§ InstalaÃ§Ã£o

### 1. Extrair os arquivos
Extraia todos os arquivos deste ZIP para um diretÃ³rio de sua escolha.

### 2. Criar ambiente virtual (recomendado)
```bash
python -m venv venv

# Linux/Mac
source venv/bin/activate

# Windows
venv\Scripts\activate
```

### 3. Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

## ğŸš€ Executar a AplicaÃ§Ã£o

### Desenvolvimento/Teste local
```bash
streamlit run app_refatorado.py
```

A aplicaÃ§Ã£o serÃ¡ aberta automaticamente em: http://localhost:8501

### ProduÃ§Ã£o

#### OpÃ§Ã£o 1: Streamlit Community Cloud
1. FaÃ§a upload dos arquivos para um repositÃ³rio GitHub
2. Acesse https://share.streamlit.io
3. Conecte seu repositÃ³rio
4. Deploy automÃ¡tico!

#### OpÃ§Ã£o 2: Docker
```bash
# Criar Dockerfile (exemplo)
FROM python:3.9-slim

WORKDIR /app
COPY . /app

RUN pip install -r requirements.txt

EXPOSE 8501

CMD ["streamlit", "run", "app_refatorado.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

```bash
# Build e executar
docker build -t i2a2-eda-agent .
docker run -p 8501:8501 i2a2-eda-agent
```

#### OpÃ§Ã£o 3: Servidor Linux com Nginx
```bash
# Instalar dependÃªncias do sistema
sudo apt-get update
sudo apt-get install python3-pip python3-venv nginx

# Configurar aplicaÃ§Ã£o
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Executar com nohup
nohup streamlit run app_refatorado.py --server.port=8501 &

# Configurar Nginx como proxy reverso
# Editar /etc/nginx/sites-available/default
location /eda-agent {
    proxy_pass http://localhost:8501;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    proxy_set_header Host $host;
}
```

## ğŸ” ConfiguraÃ§Ã£o de API Keys

O projeto usa modelos LLM gratuitos atravÃ©s do OpenRouter. 
As chaves jÃ¡ estÃ£o configuradas no cÃ³digo, mas vocÃª pode:

1. Criar sua prÃ³pria conta em https://openrouter.ai
2. Obter uma API key gratuita
3. Atualizar em `config/settings.py` ou via variÃ¡vel de ambiente:

```bash
export OPENROUTER_API_KEY="sua-chave-aqui"
```

## ğŸ“Š Modelos LLM DisponÃ­veis

- xAI Grok 4 Fast (gratuito, 100 req/dia)
- Meta Llama 3.2 3B (gratuito, 200 req/dia)
- DeepSeek Free (gratuito, 50 req/dia)

## ğŸ› Troubleshooting

### Erro ao instalar dependÃªncias
```bash
pip install --upgrade pip
pip install -r requirements.txt --force-reinstall
```

### Porta 8501 jÃ¡ em uso
```bash
streamlit run app_refatorado.py --server.port=8502
```

### Erro de memÃ³ria com datasets grandes
- Reduza o tamanho do dataset
- Aumente a memÃ³ria disponÃ­vel
- Use amostragem dos dados

## ğŸ“ˆ Monitoramento

Para produÃ§Ã£o, considere adicionar:
- Logs estruturados (jÃ¡ implementados em utils/logger.py)
- MÃ©tricas de uso (Prometheus/Grafana)
- Health checks
- Rate limiting

## ğŸ”’ SeguranÃ§a

- âœ… Dados processados localmente
- âœ… NÃ£o compartilha dados com servidores externos
- âœ… Apenas perguntas sÃ£o enviadas para LLMs
- âš ï¸ Para produÃ§Ã£o, adicione autenticaÃ§Ã£o (Streamlit Auth, OAuth, etc)

## ğŸ“ Suporte

Para problemas ou dÃºvidas:
1. Verifique README.md para documentaÃ§Ã£o completa
2. Consulte ARCHITECTURE.md para detalhes tÃ©cnicos
3. Verifique os logs em caso de erros

## ğŸ“ Checklist de Deploy

- [ ] Python 3.8+ instalado
- [ ] DependÃªncias instaladas
- [ ] AplicaÃ§Ã£o rodando localmente
- [ ] ConfiguraÃ§Ã£o de proxy/firewall (se necessÃ¡rio)
- [ ] Monitoramento configurado
- [ ] Backup dos dados configurado
- [ ] DocumentaÃ§Ã£o revisada

---
**VersÃ£o:** 2.0.3 | **Ãšltima atualizaÃ§Ã£o:** 2025
